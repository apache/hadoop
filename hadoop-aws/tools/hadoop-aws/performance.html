<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--
 | Generated by Apache Maven Doxia at 2024-10-22
 | Rendered using Apache Maven Stylus Skin 1.5
-->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Apache Hadoop Amazon Web Services support &#x2013; Maximizing Performance when working with the S3A Connector</title>
    <style type="text/css" media="all">
      @import url("../../css/maven-base.css");
      @import url("../../css/maven-theme.css");
      @import url("../../css/site.css");
    </style>
    <link rel="stylesheet" href="../../css/print.css" type="text/css" media="print" />
        <meta name="Date-Revision-yyyymmdd" content="20241022" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
                </head>
  <body class="composite">
    <div id="banner">
                        <a href="http://hadoop.apache.org/" id="bannerLeft">
                                        <img src="http://hadoop.apache.org/images/hadoop-logo.jpg" alt="" />
                </a>
                              <a href="http://www.apache.org/" id="bannerRight">
                                        <img src="http://www.apache.org/images/asf_logo_wide.png" alt="" />
                </a>
            <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                     <div class="xright">            <a href="http://wiki.apache.org/hadoop" class="externalLink">Wiki</a>
            |
                <a href="https://gitbox.apache.org/repos/asf/hadoop.git" class="externalLink">git</a>
              
                                   &nbsp;| Last Published: 2024-10-22
              &nbsp;| Version: 3.5.0-SNAPSHOT
            </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                   <h5>General</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/SingleCluster.html">Single Node Setup</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/ClusterSetup.html">Cluster Setup</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/CommandsManual.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/FileSystemShell.html">FileSystem Shell</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Compatibility.html">Compatibility Specification</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/DownstreamDev.html">Downstream Developer's Guide</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/AdminCompatibilityGuide.html">Admin Compatibility Guide</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/InterfaceClassification.html">Interface Classification</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/filesystem/index.html">FileSystem Specification</a>
            </li>
          </ul>
                       <h5>Common</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/CLIMiniCluster.html">CLI Mini Cluster</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/FairCallQueue.html">Fair Call Queue</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/NativeLibraries.html">Native Libraries</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Superusers.html">Proxy User</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/RackAwareness.html">Rack Awareness</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/SecureMode.html">Secure Mode</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/ServiceLevelAuth.html">Service Level Authorization</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/HttpAuthentication.html">HTTP Authentication</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/CredentialProviderAPI.html">Credential Provider API</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-kms/index.html">Hadoop KMS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Tracing.html">Tracing</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/UnixShellGuide.html">Unix Shell Guide</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/registry/index.html">Registry</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/AsyncProfilerServlet.html">Async Profiler</a>
            </li>
          </ul>
                       <h5>HDFS</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">User Guide</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HDFSCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">NameNode HA With QJM</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">NameNode HA With NFS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ObserverNameNode.html">Observer NameNode</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/Federation.html">Federation</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ViewFs.html">ViewFs</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ViewFsOverloadScheme.html">ViewFsOverloadScheme</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsSnapshots.html">Snapshots</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsEditsViewer.html">Edits Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html">Image Viewer</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html">Permissions and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html">Quotas and HDFS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/LibHdfs.html">libhdfs (C API)</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/WebHDFS.html">WebHDFS (REST API)</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-hdfs-httpfs/index.html">HttpFS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html">Short Circuit Local Reads</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/CentralizedCacheManagement.html">Centralized Cache Management</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html">NFS Gateway</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">Rolling Upgrade</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ExtendedAttributes.html">Extended Attributes</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html">Transparent Encryption</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsMultihoming.html">Multihoming</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html">Storage Policies</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/MemoryStorage.html">Memory Storage Support</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/SLGUserGuide.html">Synthetic Load Generator</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html">Erasure Coding</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HDFSDiskbalancer.html">Disk Balancer</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsUpgradeDomain.html">Upgrade Domain</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsDataNodeAdminGuide.html">DataNode Admin</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs-rbf/HDFSRouterFederation.html">Router Federation</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/HdfsProvidedStorage.html">Provided Storage</a>
            </li>
          </ul>
                       <h5>MapReduce</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">Tutorial</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduce_Compatibility_Hadoop1_Hadoop2.html">Compatibility with 1.x</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/EncryptedShuffle.html">Encrypted Shuffle</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html">Pluggable Shuffle/Sort</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistributedCacheDeploy.html">Distributed Cache Deploy</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/SharedCacheSupport.html">Support for YARN Shared Cache</a>
            </li>
          </ul>
                       <h5>MapReduce REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredAppMasterRest.html">MR Application Master</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html">MR History Server</a>
            </li>
          </ul>
                       <h5>YARN</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/YARN.html">Architecture</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/YarnCommands.html">Commands Reference</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">Capacity Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/FairScheduler.html">Fair Scheduler</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRestart.html">ResourceManager Restart</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">ResourceManager HA</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/ResourceModel.html">Resource Model</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeLabel.html">Node Labels</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeAttributes.html">Node Attributes</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/WebApplicationProxy.html">Web Application Proxy</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html">Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/TimelineServiceV2.html">Timeline Service V.2</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html">Writing YARN Applications</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html">YARN Application Security</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeManager.html">NodeManager</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/DockerContainers.html">Running Applications in Docker Containers</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/RuncContainers.html">Running Applications in runC Containers</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html">Using CGroups</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/SecureContainer.html">Secure Containers</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/ReservationSystem.html">Reservation System</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/GracefulDecommission.html">Graceful Decommission</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/OpportunisticContainers.html">Opportunistic Containers</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/Federation.html">YARN Federation</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/SharedCache.html">Shared Cache</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/UsingGpus.html">Using GPU</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/UsingFPGA.html">Using FPGA</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/PlacementConstraints.html">Placement Constraints</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/YarnUI2.html">YARN UI2</a>
            </li>
          </ul>
                       <h5>YARN REST APIs</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html">Introduction</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html">Resource Manager</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/NodeManagerRest.html">Node Manager</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/TimelineServer.html#Timeline_Server_REST_API_v1">Timeline Server</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/TimelineServiceV2.html#Timeline_Service_v.2_REST_API">Timeline Service V.2</a>
            </li>
          </ul>
                       <h5>YARN Service</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/yarn-service/Overview.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/yarn-service/QuickStart.html">QuickStart</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/yarn-service/Concepts.html">Concepts</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/yarn-service/YarnServiceAPI.html">Yarn Service API</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/yarn-service/ServiceDiscovery.html">Service Discovery</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-site/yarn-service/SystemServices.html">System Services</a>
            </li>
          </ul>
                       <h5>Hadoop Compatible File Systems</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-aliyun/tools/hadoop-aliyun/index.html">Aliyun OSS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-aws/tools/hadoop-aws/index.html">Amazon S3</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-azure/index.html">Azure Blob Storage</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-azure-datalake/index.html">Azure Data Lake Storage</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-cos/cloud-storage/index.html">Tencent COS</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-huaweicloud/cloud-storage/index.html">Huaweicloud OBS</a>
            </li>
          </ul>
                       <h5>Auth</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-auth/index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-auth/Examples.html">Examples</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-auth/Configuration.html">Configuration</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-auth/BuildingIt.html">Building</a>
            </li>
          </ul>
                       <h5>Tools</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-streaming/HadoopStreaming.html">Hadoop Streaming</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-archives/HadoopArchives.html">Hadoop Archives</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-archive-logs/HadoopArchiveLogs.html">Hadoop Archive Logs</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-distcp/DistCp.html">DistCp</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-federation-balance/HDFSFederationBalance.html">HDFS Federation Balance</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-gridmix/GridMix.html">GridMix</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-rumen/Rumen.html">Rumen</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-resourceestimator/ResourceEstimator.html">Resource Estimator Service</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-sls/SchedulerLoadSimulator.html">Scheduler Load Simulator</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Benchmarking.html">Hadoop Benchmarking</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-dynamometer/Dynamometer.html">Dynamometer</a>
            </li>
          </ul>
                       <h5>Reference</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/release/">Changelog and Release Notes</a>
            </li>
                  <li class="none">
                  <a href="../../../api/index.html">Java API docs</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/UnixShellAPI.html">Unix Shell API</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/Metrics.html">Metrics</a>
            </li>
          </ul>
                       <h5>Configuration</h5>
                  <ul>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/core-default.xml">core-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-hdfs-rbf/hdfs-rbf-default.xml">hdfs-rbf-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml">mapred-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-kms/kms-default.html">kms-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-hdfs-httpfs/httpfs-default.html">httpfs-default.xml</a>
            </li>
                  <li class="none">
                  <a href="../../../hadoop-project-dist/hadoop-common/DeprecatedProperties.html">Deprecated Properties</a>
            </li>
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          <img alt="Built by Maven" src="../../images/logos/maven-feather.png"/>
        </a>
                       
                               </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <!---
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<h1>Maximizing Performance when working with the S3A Connector</h1>
<ul>
<li><a href="#Introduction"> Introduction</a></li>
<li><a href="#Improving_read_performance_using_Vectored_IO"> Improving read performance using Vectored IO</a></li>
<li><a href="#Improving_delete_performance_through_bulkdelete_API."> Improving delete performance through bulkdelete API.</a>
<ul>
<li><a href="#S3A_Implementation_of_Bulk_Delete.">S3A Implementation of Bulk Delete.</a></li>
<li><a href="#S3_Scalability_and_Performance">S3 Scalability and Performance</a></li></ul></li>
<li><a href="#Improving_data_input_performance_through_fadvise"> Improving data input performance through fadvise</a>
<ul>
<li><a href="#fadvise_sequential.2C_whole-file">fadvise sequential, whole-file</a></li>
<li><a href="#fadvise_random">fadvise random</a></li>
<li><a href="#fadvise_normal_or_adaptive_.28default.29">fadvise normal or adaptive (default)</a></li></ul></li>
<li><a href="#Committing_Work_in_MapReduce_and_Spark"> Committing Work in MapReduce and Spark</a></li>
<li><a href="#Options_to_Tune"> Options to Tune</a>
<ul>
<li><a href="#Performance_Flags:_fs.s3a.performance.flag"> Performance Flags: fs.s3a.performance.flag</a></li>
<li><a href="#Create_Performance_fs.s3a.create.performance"> Create Performance fs.s3a.create.performance</a></li>
<li><a href="#Mkdir_Performance"> Mkdir Performance</a></li>
<li><a href="#Thread_and_connection_pool_settings."> Thread and connection pool settings.</a></li>
<li><a href="#Timeouts."> Timeouts.</a></li>
<li><a href="#For_large_data_uploads.2C_tune_the_block_size:_fs.s3a.block.size">For large data uploads, tune the block size: fs.s3a.block.size</a></li>
<li><a href="#Maybe:_Buffer_Write_Data_in_Memory">Maybe: Buffer Write Data in Memory</a></li></ul></li>
<li><a href="#DistCP"> DistCP</a>
<ul>
<li><a href="#DistCP:_Options_to_Tune">DistCP: Options to Tune</a></li>
<li><a href="#DistCP:_Options_to_Avoid.">DistCP: Options to Avoid.</a></li>
<li><a href="#DistCP:_Parameters_to_Tune">DistCP: Parameters to Tune</a></li></ul></li>
<li><a href="#hadoop_shell_commands_fs_-rm"> hadoop shell commands fs -rm</a></li>
<li><a href="#Improving_S3_load-balancing_behavior"> Improving S3 load-balancing behavior</a></li>
<li><a href="#Troubleshooting_network_performance"> Troubleshooting network performance</a></li>
<li><a href="#Throttling"> Throttling</a>
<ul>
<li><a href="#Tips_to_Keep_Throttling_down"> Tips to Keep Throttling down</a></li></ul></li>
<li><a href="#Best_Practises_for_Code"> Best Practises for Code</a>
<ul>
<li><a href="#rename.28.29">rename()</a></li>
<li><a href="#delete.28path.2C_recursive.29">delete(path, recursive)</a></li></ul></li>
<li><a href="#Tuning_SSL_Performance"> Tuning SSL Performance</a>
<ul>
<li><a href="#OpenSSL_Acceleration"> OpenSSL Acceleration</a></li>
<li><a href="#fs.s3a.ssl.channel.mode_Configuration">fs.s3a.ssl.channel.mode Configuration</a></li>
<li><a href="#WildFly_classpath_and_SSL_library_requirements">WildFly classpath and SSL library requirements</a></li></ul></li>
<li><a href="#Tuning_FileSystem_Initialization."> Tuning FileSystem Initialization.</a>
<ul>
<li><a href="#Bucket_existence_checks">Bucket existence checks</a></li>
<li><a href="#Rate_limiting_parallel_FileSystem_creation_operations">Rate limiting parallel FileSystem creation operations</a></li></ul></li></ul>
<section>
<h2><a name="Introduction"></a><a name="introduction"></a> Introduction</h2>
<p>S3 is slower to work with than HDFS, even on virtual clusters running on Amazon EC2.</p>
<p>That&#x2019;s because its a very different system, as you can see:</p>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th> Feature </th>
<th> HDFS </th>
<th> S3 through the S3A connector </th></tr>
</thead><tbody>

<tr class="b">
<td> communication </td>
<td> RPC </td>
<td> HTTP GET/PUT/HEAD/LIST/COPY requests </td></tr>
<tr class="a">
<td> data locality </td>
<td> local storage </td>
<td> remote S3 servers </td></tr>
<tr class="b">
<td> replication </td>
<td> multiple datanodes </td>
<td> asynchronous after upload </td></tr>
<tr class="a">
<td> consistency </td>
<td> consistent data and listings </td>
<td> consistent since November 2020</td></tr>
<tr class="b">
<td> bandwidth </td>
<td> best: local IO, worst: datacenter network </td>
<td> bandwidth between servers and S3 </td></tr>
<tr class="a">
<td> latency </td>
<td> low </td>
<td> high, especially for &#x201c;low cost&#x201d; directory operations </td></tr>
<tr class="b">
<td> rename </td>
<td> fast, atomic </td>
<td> slow faked rename through COPY and DELETE</td></tr>
<tr class="a">
<td> delete </td>
<td> fast, atomic </td>
<td> fast for a file, slow and non-atomic for directories </td></tr>
<tr class="b">
<td> writing</td>
<td> incremental </td>
<td> in blocks; not visible until the writer is closed </td></tr>
<tr class="a">
<td> reading </td>
<td> seek() is fast </td>
<td> seek() is slow and expensive </td></tr>
<tr class="b">
<td> IOPs </td>
<td> limited only by hardware </td>
<td> callers are throttled to shards in an s3 bucket </td></tr>
<tr class="a">
<td> Security </td>
<td> Posix user+group; ACLs </td>
<td> AWS Roles and policies </td></tr>
</tbody>
</table>
<p>From a performance perspective, key points to remember are:</p>
<ul>

<li>S3 throttles bucket access across all callers: adding workers can make things worse.</li>
<li>EC2 VMs have network IO throttled based on the VM type.</li>
<li>Directory rename and copy operations take <i>much</i> longer the more objects and data there is. The slow performance of <code>rename()</code> surfaces during the commit phase of jobs, applications like <code>DistCP</code>, and elsewhere.</li>
<li>seek() calls when reading a file can force new HTTP requests. This can make reading columnar Parquet/ORC data expensive.</li>
</ul>
<p>Overall, although the S3A connector makes S3 look like a file system, it isn&#x2019;t, and some attempts to preserve the metaphor are &#x201c;aggressively suboptimal&#x201d;.</p>
<p>To make most efficient use of S3, care is needed.</p></section><section>
<h2><a name="Improving_read_performance_using_Vectored_IO"></a><a name="vectoredIO"></a> Improving read performance using Vectored IO</h2>
<p>The S3A FileSystem supports implementation of vectored read api using which a client can provide a list of file ranges to read returning a future read object associated with each range. For full api specification please see <a href="../../../../../../hadoop-common-project/hadoop-common/target/site/filesystem/fsdatainputstream.html">FSDataInputStream</a>.</p>
<p>The following properties can be configured to optimise vectored reads based on the client requirements.</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.vectored.read.min.seek.size&lt;/name&gt;
  &lt;value&gt;4K&lt;/value&gt;
  &lt;description&gt;
     What is the smallest reasonable seek in bytes such
     that we group ranges together during vectored
     read operation.
   &lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
   &lt;name&gt;fs.s3a.vectored.read.max.merged.size&lt;/name&gt;
   &lt;value&gt;1M&lt;/value&gt;
   &lt;description&gt;
      What is the largest merged read size in bytes such
      that we group ranges together during vectored read.
      Setting this value to 0 will disable merging of ranges.
   &lt;/description&gt;
&lt;property&gt;
   &lt;name&gt;fs.s3a.vectored.active.ranged.reads&lt;/name&gt;
   &lt;value&gt;4&lt;/value&gt;
   &lt;description&gt;
      Maximum number of range reads a single input stream can have
      active (downloading, or queued) to the central FileSystem
      instance's pool of queued operations.
      This stops a single stream overloading the shared thread pool.
   &lt;/description&gt;
&lt;/property&gt;
</pre></div></div>
</section><section>
<h2><a name="Improving_delete_performance_through_bulkdelete_API."></a><a name="bulkdelete"></a> Improving delete performance through bulkdelete API.</h2>
<p>For bulk delete API spec refer to File System specification. <a href="../../../../../../hadoop-common-project/hadoop-common/target/site/filesystem/bulkdelete.html">BulkDelete</a></p>
<p>The S3A client exports this API.</p><section>
<h3><a name="S3A_Implementation_of_Bulk_Delete."></a>S3A Implementation of Bulk Delete.</h3>
<p>If multi-object delete is enabled (<code>fs.s3a.multiobjectdelete.enable</code> = true), as it is by default, then the page size is limited to that defined in <code>fs.s3a.bulk.delete.page.size</code>, which MUST be less than or equal to 1000. * The entire list of paths to delete is aggregated into a single bulk delete request, issued to the store. * Provided the caller has the correct permissions, every entry in the list will, if the path references an object, cause that object to be deleted. * If the path does not reference an object: the path will not be deleted &#x201c;This is for deleting objects, not directories&#x201d; * No probes for the existence of parent directories will take place; no parent directory markers will be created. &#x201c;If you need parent directories, call mkdir() yourself&#x201d; * The list of failed keys listed in the <code>DeleteObjectsResponse</code> response are converted into paths and returned along with their error messages. * Network and other IO errors are raised as exceptions.</p>
<p>If multi-object delete is disabled (or the list of size 1) * A single <code>DELETE</code> call is issued * Any <code>AccessDeniedException</code> raised is converted to a result in the error list. * Any 404 response from a (non-AWS) store will be ignored. * Network and other IO errors are raised as exceptions.</p>
<p>Because there are no probes to ensure the call does not overwrite a directory, or to see if a parentDirectory marker needs to be created, this API is still faster than issuing a normal <code>FileSystem.delete(path)</code> call.</p>
<p>That is: all the overhead normally undertaken to preserve the Posix System model are omitted.</p></section><section>
<h3><a name="S3_Scalability_and_Performance"></a>S3 Scalability and Performance</h3>
<p>Every entry in a bulk delete request counts as one write operation against AWS S3 storage. With the default write rate under a prefix on AWS S3 Standard storage restricted to 3,500 writes/second, it is very easy to overload the store by issuing a few bulk delete requests simultaneously.</p>
<ul>

<li>If throttling is triggered then all clients interacting with the store may observe performance issues.</li>
<li>The write quota applies even for paths which do not exist.</li>
<li>The S3A client <i>may</i> perform rate throttling as well as page size limiting.</li>
</ul>
<p>What does that mean? it means that attempting to issue multiple bulk delete calls in parallel can be counterproductive.</p>
<p>When overloaded, the S3 store returns a 403 throttle response. This will trigger it back off and retry of posting the request. However, the repeated request will still include the same number of objects and <i>so generate the same load</i>.</p>
<p>This can lead to a pathological situation where the repeated requests will never be satisfied because the request itself is sufficient to overload the store. See [HADOOP-16823.Large DeleteObject requests are their own Thundering Herd] (<a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-16823">https://issues.apache.org/jira/browse/HADOOP-16823</a>) for an example of where this did actually surface in production.</p>
<p>This is why the default page size of S3A clients is 250 paths, not the store limit of 1000 entries. It is also why the S3A delete/rename operations do not attempt to do massive parallel deletions, Instead bulk delete requests are queued for a single blocking thread to issue. Consider a similar design.</p>
<p>When working with versioned S3 buckets, every path deleted will add a tombstone marker to the store at that location, even if there was no object at that path. While this has no negative performance impact on the bulk delete call, it will slow down list requests subsequently made against that path. That is: bulk delete requests of paths which do not exist will hurt future queries.</p>
<p>Avoid this. Note also that TPC-DS Benchmark do not create the right load to make the performance problems observable -but they can surface in production. * Configure buckets to have a limited number of days for tombstones to be preserved. * Do not delete paths which you know reference nonexistent files or directories.</p></section></section><section>
<h2><a name="Improving_data_input_performance_through_fadvise"></a><a name="fadvise"></a> Improving data input performance through fadvise</h2>
<p>The S3A Filesystem client supports the notion of input policies, similar to that of the Posix <code>fadvise()</code> API call. This tunes the behavior of the S3A client to optimise HTTP GET requests for the different use cases.</p>
<p>The list of supported options is found in <a href="../../../../../../hadoop-common-project/hadoop-common/target/site/filesystem/fsdatainputstreambuilder.html">FSDataInputStream</a>.</p><section>
<h3><a name="fadvise_sequential.2C_whole-file"></a>fadvise <code>sequential</code>, <code>whole-file</code></h3>
<p>Read through the file, possibly with some short forward seeks.</p>
<p>The whole document is requested in a single HTTP request; forward seeks within the readahead range are supported by skipping over the intermediate data.</p>
<p>This delivers maximum sequential throughput &#x2014;but with very expensive backward seeks.</p>
<p>Applications reading a file in bulk (DistCP, any copy operations) should use sequential access, as should those reading data from gzipped <code>.gz</code> files. Because the &#x201c;normal&#x201d; fadvise policy starts off in sequential IO mode, there is rarely any need to explicit request this policy.</p>
<p>Distcp will automatically request <code>whole-file</code> access, even on deployments where the cluster configuration is for <code>random</code> IO.</p></section><section>
<h3><a name="fadvise_random"></a>fadvise <code>random</code></h3>
<p>Optimised for random IO, specifically the Hadoop <code>PositionedReadable</code> operations &#x2014;though <code>seek(offset); read(byte_buffer)</code> also benefits.</p>
<p>Rather than ask for the whole file, the range of the HTTP request is set to the length of data desired in the <code>read</code> operation (Rounded up to the readahead value set in <code>setReadahead()</code> if necessary).</p>
<p>By reducing the cost of closing existing HTTP requests, this is highly efficient for file IO accessing a binary file through a series of <code>PositionedReadable.read()</code> and <code>PositionedReadable.readFully()</code> calls. Sequential reading of a file is expensive, as now many HTTP requests must be made to read through the file: there&#x2019;s a delay between each GET operation.</p>
<p>Random IO is best for IO with seek-heavy characteristics:</p>
<ul>

<li>Data is read using the <code>PositionedReadable</code> API.</li>
<li>Long distance (many MB) forward seeks</li>
<li>Backward seeks as likely as forward seeks.</li>
<li>Little or no use of single character <code>read()</code> calls or small <code>read(buffer)</code> calls.</li>
<li>Applications running close to the S3 data store. That is: in EC2 VMs in the same datacenter as the S3 instance.</li>
</ul>
<p>The desired fadvise policy must be set in the configuration option <code>fs.s3a.experimental.input.fadvise</code> when the filesystem instance is created. That is: it can only be set on a per-filesystem basis, not on a per-file-read basis.</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.experimental.input.fadvise&lt;/name&gt;
  &lt;value&gt;random&lt;/value&gt;
  &lt;description&gt;
  Policy for reading files.
  Values: 'random', 'sequential' or 'normal'
   &lt;/description&gt;
&lt;/property&gt;
</pre></div></div>

<p><a class="externalLink" href="https://issues.apache.org/jira/browse/HDFS-2744">HDFS-2744</a>, <i>Extend FSDataInputStream to allow fadvise</i> proposes adding a public API to set fadvise policies on input streams. Once implemented, this will become the supported mechanism used for configuring the input IO policy.</p></section><section>
<h3><a name="fadvise_normal_or_adaptive_.28default.29"></a>fadvise <code>normal</code> or <code>adaptive</code> (default)</h3>
<p>The <code>normal</code> policy starts off reading a file  in <code>sequential</code> mode, but if the caller seeks backwards in the stream, it switches from sequential to <code>random</code>.</p>
<p>This policy essentially recognizes the initial read pattern of columnar storage formats (e.g. Apache ORC and Apache Parquet), which seek to the end of a file, read in index data and then seek backwards to selectively read columns. The first seeks may be expensive compared to the random policy, however the overall process is much less expensive than either sequentially reading through a file with the <code>random</code> policy, or reading columnar data with the <code>sequential</code> policy.</p></section></section><section>
<h2><a name="Committing_Work_in_MapReduce_and_Spark"></a><a name="commit"></a> Committing Work in MapReduce and Spark</h2>
<p>Hadoop MapReduce, Apache Hive and Apache Spark all write their work to HDFS and similar filesystems. When using S3 as a destination, this is slow because of the way <code>rename()</code> is mimicked with copy and delete.</p>
<p>If committing output takes a long time, it is because you are using the standard <code>FileOutputCommitter</code>.</p>
<p><i>Your problem may appear to be performance, but that is a symptom of the underlying problem: the way S3A fakes rename operations means that the rename cannot be safely be used in output-commit algorithms.</i></p>
<p>Fix: Use one of the dedicated <a href="committers.html">S3A Committers</a>.</p></section><section>
<h2><a name="Options_to_Tune"></a><a name="tuning"></a> Options to Tune</h2><section>
<h3><a name="Performance_Flags:_fs.s3a.performance.flag"></a><a name="flags"></a> Performance Flags: <code>fs.s3a.performance.flag</code></h3>
<p>This option takes a comma separated list of performance flags. View it as the equivalent of the <code>-O</code> compiler optimization list C/C++ compilers offer. That is a complicated list of options which deliver speed if the person setting them understands the risks.</p>
<ul>

<li>The list of flags MAY change across releases</li>
<li>The semantics of specific flags SHOULD NOT change across releases.</li>
<li>If an option is to be tuned which may relax semantics, a new option MUST be defined.</li>
<li>Unknown flags are ignored; this is to avoid compatibility.</li>
<li>The option <code>*</code> means &#x201c;turn everything on&#x201d;. This is implicitly unstable across releases.</li>
</ul>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th> <i>Option</i> </th>
<th> <i>Meaning</i>          </th>
<th align="left"> Since </th></tr>
</thead><tbody>

<tr class="b">
<td> <code>create</code> </td>
<td> Create Performance </td>
<td align="left"> 3.4.1 </td></tr>
<tr class="a">
<td> <code>mkdir</code>  </td>
<td> Mkdir Performance  </td>
<td align="left"> 3.4.1 </td></tr>
</tbody>
</table>
<ul>

<li>The <code>create</code> flag has the same semantics as <a href="#create-performance"><code>fs.s3a.create.performance</code></a></li>
<li>The <code>mkdir</code> flag semantics are explained in <a href="#mkdir-performance">Mkdir Performance</a></li>
</ul></section><section>
<h3><a name="Create_Performance_fs.s3a.create.performance"></a><a name="create-performance"></a> Create Performance <code>fs.s3a.create.performance</code></h3>
<p>The configuration option <code>fs.s3a.create.performance</code> has the same behavior as the <code>fs.s3a.performance.flag</code> flag option <code>create</code>:</p>
<ul>

<li>No overwrite checks are made when creating a file, even if overwrite is set to <code>false</code> in the application/library code</li>
<li>No checks are made for an object being written above a path containing other objects (i.e. a &#x201c;directory&#x201d;)</li>
<li>No checks are made for a parent path containing an object which is not a directory marker (i.e. a &#x201c;file&#x201d;)</li>
</ul>
<p>This saves multiple probes per operation, especially a <code>LIST</code> call.</p>
<p>It may however result in * Unintentional overwriting of data * Creation of directory structures which can no longer be navigated through filesystem APIs.</p>
<p>Use with care, and, ideally, enable versioning on the S3 store.</p></section><section>
<h3><a name="Mkdir_Performance"></a><a name="mkdir-performance"></a> Mkdir Performance</h3>
<p><code>fs.s3a.performance.flag</code> flag option <code>mkdir</code>:</p>
<ul>

<li>Mkdir does not check whether the parent is directory or file.</li>
</ul>
<p>This avoids the verification of the file status of the parent file or the closest ancestor. Unlike the default mkdir operation, if the parent is not a directory, the mkdir operation does not throw any error.</p>
<p>This option can help with mkdir performance improvement but must be used only if the person setting them understands the above-mentioned risk.</p></section><section>
<h3><a name="Thread_and_connection_pool_settings."></a><a name="threads"></a> Thread and connection pool settings.</h3>
<p>Each S3A client interacting with a single bucket, as a single user, has its own dedicated pool of open HTTP connections alongside a pool of threads used for background/parallel operations in addition to the worker threads of the actual application.</p>
<p>The default pool sizes are intended to strike a balance between performance and memory/thread use.</p>
<p>You can have a larger pool of (reused) HTTP connections and threads for parallel IO (especially uploads, prefetching and vector reads) by setting the appropriate properties. Note: S3A Connectors have their own thread pools for job commit, but everything uses the same HTTP connection pool.</p>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th> Property                       </th>
<th> Default </th>
<th> Meaning                                                          </th></tr>
</thead><tbody>

<tr class="b">
<td> <code>fs.s3a.threads.max</code>           </td>
<td> <code>96</code>    </td>
<td> Threads in the thread pool                                       </td></tr>
<tr class="a">
<td> <code>fs.s3a.threads.keepalivetime</code> </td>
<td> <code>60s</code>   </td>
<td> Expiry time for idle threads in the thread pool                  </td></tr>
<tr class="b">
<td> <code>fs.s3a.executor.capacity</code>     </td>
<td> <code>16</code>    </td>
<td> Maximum threads for any single operation                         </td></tr>
<tr class="a">
<td> <code>fs.s3a.max.total.tasks</code>       </td>
<td> <code>16</code>    </td>
<td> Extra tasks which can be queued excluding prefetching operations </td></tr>
</tbody>
</table></section><section>
<h3><a name="Timeouts."></a><a name="timeouts"></a> Timeouts.</h3>
<p>Network timeout options can be tuned to make the client fail faster <i>or</i> retry more. The choice is yours. Generally recovery is better, but sometimes fail-fast is more useful.</p>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th> Property                                </th>
<th> Default </th>
<th align="left"> V2  </th>
<th> Meaning                                               </th></tr>
</thead><tbody>

<tr class="b">
<td> <code>fs.s3a.connection.maximum</code>             </td>
<td> <code>500</code>   </td>
<td align="left">     </td>
<td> Connection pool size                                  </td></tr>
<tr class="a">
<td> <code>fs.s3a.connection.keepalive</code>           </td>
<td> <code>false</code> </td>
<td align="left"> <code>*</code> </td>
<td> Use TCP keepalive on open channels                    </td></tr>
<tr class="b">
<td> <code>fs.s3a.connection.acquisition.timeout</code> </td>
<td> <code>60s</code>   </td>
<td align="left"> <code>*</code> </td>
<td> Timeout for waiting for a connection from the pool.   </td></tr>
<tr class="a">
<td> <code>fs.s3a.connection.establish.timeout</code>   </td>
<td> <code>30s</code>   </td>
<td align="left">     </td>
<td> Time to establish the TCP/TLS connection              </td></tr>
<tr class="b">
<td> <code>fs.s3a.connection.idle.time</code>           </td>
<td> <code>60s</code>   </td>
<td align="left"> <code>*</code> </td>
<td> Maximum time for idle HTTP connections in the pool    </td></tr>
<tr class="a">
<td> <code>fs.s3a.connection.request.timeout</code>     </td>
<td> <code>60s</code>   </td>
<td align="left">     </td>
<td> If greater than zero, maximum time for a response     </td></tr>
<tr class="b">
<td> <code>fs.s3a.connection.timeout</code>             </td>
<td> <code>200s</code>  </td>
<td align="left">     </td>
<td> Timeout for socket problems on a TCP channel          </td></tr>
<tr class="a">
<td> <code>fs.s3a.connection.ttl</code>                 </td>
<td> <code>5m</code>    </td>
<td align="left">     </td>
<td> Lifetime of HTTP connections from the pool            </td></tr>
</tbody>
</table>
<p>Units: 1. The default unit for all these options except for <code>fs.s3a.threads.keepalivetime</code> is milliseconds, unless a time suffix is declared. 2. Versions of Hadoop built with the AWS V1 SDK <i>only</i> support milliseconds rather than suffix values. If configurations are intended to apply across hadoop releases, you MUST use milliseconds without a suffix. 3. <code>fs.s3a.threads.keepalivetime</code> has a default unit of seconds on all hadoop releases. 4. Options flagged as &#x201c;V2&#x201d; are new with the AWS V2 SDK; they are ignored on V1 releases.</p><hr />
<p>There are some hard tuning decisions related to pool size and expiry. As servers add more cores and services add many more worker threads, a larger pool size is more and more important: the default values in <code>core-default.xml</code> have been slowly increased over time but should be treated as &#x201c;the best&#x201d;, simply what is considered a good starting case. With Vectored IO adding multiple GET requests per Spark/Hive worker thread, and stream prefetching performing background block prefetch, larger pool and thread sizes are even more important.</p>
<p>In large hive deployments, thread and connection pools of thousands have been known to have been set.</p>
<p>Small pool: small value in <code>fs.s3a.connection.maximum</code>. * Keeps network/memory cost of having many S3A instances in the same process low. * But: limit on how many connections can be open at at a time.</p>
<ul>

<li>Large Pool. More HTTP connections can be created and kept, but cost of keeping network connections increases unless idle time is reduced through <code>fs.s3a.connection.idle.time</code>.</li>
</ul>
<p>If exceptions are raised with about timeouts acquiring connections from the pool, this can be a symptom of * Heavy load. Increase pool size and acquisition timeout <code>fs.s3a.connection.acquisition.timeout</code> * Process failing to close open input streams from the S3 store. Fix: Find uses of <code>open()</code>/<code>openFile()</code> and make sure that the streams are being <code>close()d</code></p>
<p><i>Retirement of HTTP Connections.</i></p>
<p>Connections are retired from the pool by <code>fs.s3a.connection.idle.time</code>, the maximum time for idle connections, and <code>fs.s3a.connection.ttl</code>, the maximum life of any connection in the pool, even if it repeatedly reused.</p>
<p>Limiting idle time saves on network connections, at the cost of requiring new connections on subsequent S3 operations.</p>
<p>Limiting connection TTL is useful to spread across load balancers and recover from some network connection problems, including those caused by proxies.</p>
<p><i>Request timeout</i>: <code>fs.s3a.connection.request.timeout</code></p>
<p>If set, this sets an upper limit on any non-streaming API call (i.e. everything but <code>GET</code>).</p>
<p>A timeout is good to detect and recover from failures. However, it also sets a limit on the duration of a POST/PUT of data -which, if after a timeout, will only be repeated, ultimately to failure.</p></section><section>
<h3><a name="For_large_data_uploads.2C_tune_the_block_size:_fs.s3a.block.size"></a>For large data uploads, tune the block size: <code>fs.s3a.block.size</code></h3>
<p>When uploading data, it is uploaded in blocks set by the option <code>fs.s3a.block.size</code>; default value &#x201c;32M&#x201d; for 32 Megabytes.</p>
<p>If a larger value is used, then more data is buffered before the upload begins:</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.block.size&lt;/name&gt;
  &lt;value&gt;128M&lt;/value&gt;
&lt;/property&gt;
</pre></div></div>

<p>This means that fewer PUT/POST requests are made of S3 to upload data, which reduces the likelihood that S3 will throttle the client(s)</p></section><section>
<h3><a name="Maybe:_Buffer_Write_Data_in_Memory"></a>Maybe: Buffer Write Data in Memory</h3>
<p>When large files are being uploaded, blocks are saved to disk and then queued for uploading, with multiple threads uploading different blocks in parallel.</p>
<p>The blocks can be buffered in memory by setting the option <code>fs.s3a.fast.upload.buffer</code> to <code>bytebuffer</code>, or, for on-heap storage <code>array</code>.</p>
<ol style="list-style-type: decimal">

<li>Switching to in memory-IO reduces disk IO, and can be faster if the bandwidth to the S3 store is so high that the disk IO becomes the bottleneck. This can have a tangible benefit when working with on-premise S3-compatible object stores with very high bandwidth to servers.</li>
</ol>
<p>It is very easy to run out of memory when buffering to it; the option <code>fs.s3a.fast.upload.active.blocks&quot;</code> exists to tune how many active blocks a single output stream writing to S3 may have queued at a time.</p>
<p>As the size of each buffered block is determined by the value of <code>fs.s3a.block.size</code>, the larger the block size, the more likely you will run out of memory.</p></section></section><section>
<h2><a name="DistCP"></a><a name="distcp"></a> DistCP</h2>
<p>DistCP can be slow, especially if the parameters and options for the operation are not tuned for working with S3.</p>
<p>To exacerbate the issue, DistCP invariably puts heavy load against the bucket being worked with, which will cause S3 to throttle requests. It will throttle: directory operations, uploads of new data, and delete operations, amongst other things</p><section>
<h3><a name="DistCP:_Options_to_Tune"></a>DistCP: Options to Tune</h3>
<ul>

<li><code>-numListstatusThreads &lt;threads&gt;</code> : set to something higher than the default (1).</li>
<li><code>-bandwidth &lt;mb&gt;</code> : use to limit the upload bandwidth per worker</li>
<li><code>-m &lt;maps&gt;</code> : limit the number of mappers, hence the load on the S3 bucket.</li>
</ul>
<p>Adding more maps with the <code>-m</code> option does not guarantee better performance; it may just increase the amount of throttling which takes place. A smaller number of maps with a higher bandwidth per map can be more efficient.</p></section><section>
<h3><a name="DistCP:_Options_to_Avoid."></a>DistCP: Options to Avoid.</h3>
<p>DistCp&#x2019;s <code>-atomic</code> option copies up data into a directory, then renames it into place, which is the where the copy takes place. This is a performance killer.</p>
<ul>

<li>Do not use the <code>-atomic</code> option.</li>
<li>The <code>-append</code> operation is not supported on S3; avoid.</li>
<li><code>-p</code> S3 does not have a POSIX-style permission model; this will fail.</li>
</ul></section><section>
<h3><a name="DistCP:_Parameters_to_Tune"></a>DistCP: Parameters to Tune</h3>
<ol style="list-style-type: decimal">

<li>

<p>As discussed <a href="#pooling">earlier</a>, use large values for <code>fs.s3a.threads.max</code> and <code>fs.s3a.connection.maximum</code>.</p>
</li>
<li>

<p>Perform listings in parallel by setting <code>-numListstatusThreads</code> to a higher number. Make sure that <code>fs.s3a.connection.maximum</code> is equal to or greater than the value used.</p>
</li>
<li>

<p>If using <code>-delete</code>, set <code>fs.trash.interval</code> to 0 to avoid the deleted objects from being copied to a trash directory.</p>
</li>
<li>

<p>If using distcp to upload to a new path where no existing data exists, consider adding the option <code>create</code> to the flags in <code>fs.s3a.performance.flag</code>.</p>
</li>
</ol>
<p><i>DO NOT</i> switch <code>fs.s3a.fast.upload.buffer</code> to buffer in memory. If one distcp mapper runs out of memory it will fail, and that runs the risk of failing the entire job. It is safer to keep the default value, <code>disk</code>.</p>
<p>What is potentially useful is uploading in bigger blocks; this is more efficient in terms of HTTP connection use, and reduce the IOP rate against the S3 bucket/shard.</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.block.size&lt;/name&gt;
  &lt;value&gt;128M&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.fast.upload.buffer&lt;/name&gt;
  &lt;value&gt;disk&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.trash.interval&lt;/name&gt;
  &lt;value&gt;0&lt;/value&gt;
&lt;/property&gt;

&lt;!-- maybe --&gt;
&lt;property&gt;
  &lt;name&gt;fs.s3a.create.performance&lt;/name&gt;
  &lt;value&gt;create&lt;/value&gt;
&lt;/property&gt;
</pre></div></div>
</section></section><section>
<h2><a name="hadoop_shell_commands_fs_-rm"></a><a name="rm"></a> hadoop shell commands <code>fs -rm</code></h2>
<p>The <code>hadoop fs -rm</code> command can rename the file under <code>.Trash</code> rather than deleting it. Use <code>-skipTrash</code> to eliminate that step.</p>
<p>This can be set in the property <code>fs.trash.interval</code>; while the default is 0, most HDFS deployments have it set to a non-zero value to reduce the risk of data loss.</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.trash.interval&lt;/name&gt;
  &lt;value&gt;0&lt;/value&gt;
&lt;/property&gt;
</pre></div></div>
</section><section>
<h2><a name="Improving_S3_load-balancing_behavior"></a><a name="load_balancing"></a> Improving S3 load-balancing behavior</h2>
<p>Amazon S3 uses a set of front-end servers to provide access to the underlying data. The choice of which front-end server to use is handled via load-balancing DNS service: when the IP address of an S3 bucket is looked up, the choice of which IP address to return to the client is made based on the current load of the front-end servers.</p>
<p>Over time, the load across the front-end changes, so those servers considered &#x201c;lightly loaded&#x201d; will change. If the DNS value is cached for any length of time, your application may end up talking to an overloaded server. Or, in the case of failures, trying to talk to a server that is no longer there.</p>
<p>And by default, for historical security reasons in the era of applets, the DNS TTL of a JVM is &#x201c;infinity&#x201d;.</p>
<p>To work with AWS better, set the DNS time-to-live of an application which works with S3 to something lower. See <a class="externalLink" href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/java-dg-jvm-ttl.html">AWS documentation</a>.</p></section><section>
<h2><a name="Troubleshooting_network_performance"></a><a name="network_performance"></a> Troubleshooting network performance</h2>
<p>An example of this is covered in <a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-13871">HADOOP-13871</a>.</p>
<ol style="list-style-type: decimal">

<li>

<p>For public data, use <code>curl</code>:</p>

<div class="source">
<div class="source">
<pre>curl -O https://noaa-cors-pds.s3.amazonaws.com/raw/2023/001/akse/AKSE001a.23_.gz
</pre></div></div>
</li>
<li>

<p>Use <code>nettop</code> to monitor a processes connections.</p>
</li>
</ol></section><section>
<h2><a name="Throttling"></a><a name="throttling"></a> Throttling</h2>
<p>When many requests are made of a specific S3 bucket (or shard inside it), S3 will respond with a 503 &#x201c;throttled&#x201d; response. Throttling can be recovered from, provided overall load decreases. Furthermore, because it is sent before any changes are made to the object store, is inherently idempotent. For this reason, the client will always attempt to retry throttled requests.</p>
<p>The limit of the number of times a throttled request can be retried, and the exponential interval increase between attempts, can be configured independently of the other retry limits.</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.retry.throttle.limit&lt;/name&gt;
  &lt;value&gt;20&lt;/value&gt;
  &lt;description&gt;
    Number of times to retry any throttled request.
  &lt;/description&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;fs.s3a.retry.throttle.interval&lt;/name&gt;
  &lt;value&gt;500ms&lt;/value&gt;
  &lt;description&gt;
    Interval between retry attempts on throttled requests.
  &lt;/description&gt;
&lt;/property&gt;
</pre></div></div>

<p>If a client is failing due to <code>AWSServiceThrottledException</code> failures, increasing the interval and limit <i>may</i> address this. However, it it is a sign of AWS services being overloaded by the sheer number of clients and rate of requests. Spreading data across different buckets, and/or using a more balanced directory structure may be beneficial. Consult <a class="externalLink" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html">the AWS documentation</a>.</p>
<p>Reading or writing data encrypted with SSE-KMS or DSSE-KMS forces S3 to make calls of the AWS KMS Key Management Service, which comes with its own <a class="externalLink" href="http://docs.aws.amazon.com/kms/latest/developerguide/limits.html">Request Rate Limits</a>. These default to 1200/second for an account, across all keys and all uses of them, which, for S3 means: across all buckets with data encrypted with SSE-KMS.</p><section>
<h3><a name="Tips_to_Keep_Throttling_down"></a><a name="minimizing_throttling"></a> Tips to Keep Throttling down</h3>
<p>If you are seeing a lot of throttling responses on a large scale operation like a <code>distcp</code> copy, <i>reduce</i> the number of processes trying to work with the bucket (for distcp: reduce the number of mappers with the <code>-m</code> option).</p>
<p>If you are reading or writing lists of files, if you can randomize the list so they are not processed in a simple sorted order, you may reduce load on a specific shard of S3 data, so potentially increase throughput.</p>
<p>An S3 Bucket is throttled by requests coming from all simultaneous clients. Different applications and jobs may interfere with each other: consider that when troubleshooting. Partitioning data into different buckets may help isolate load here.</p>
<p>If you are using data encrypted with SSE-KMS, then the will also apply: these are stricter than the S3 numbers. If you believe that you are reaching these limits, you may be able to get them increased. Consult <a class="externalLink" href="http://docs.aws.amazon.com/kms/latest/developerguide/limits.html">the KMS Rate Limit documentation</a>.</p></section></section><section>
<h2><a name="Best_Practises_for_Code"></a><a name="coding"></a> Best Practises for Code</h2>
<p>Here are some best practises if you are writing applications to work with S3 or any other object store through the Hadoop APIs.</p>
<p>Use <code>listFiles(path, recursive)</code> over <code>listStatus(path)</code>. The recursive <code>listFiles()</code> call can enumerate all dependents of a path in a single LIST call, irrespective of how deep the path is. In contrast, any directory tree-walk implemented in the client is issuing multiple HTTP requests to scan each directory, all the way down.</p>
<p>Cache the outcome of <code>getFileStats()</code>, rather than repeatedly ask for it. That includes using <code>isFile()</code>, <code>isDirectory()</code>, which are simply wrappers around <code>getFileStatus()</code>.</p>
<p>Rely on <code>FileNotFoundException</code> being raised if the source of an operation is missing, rather than implementing your own probe for the file before conditionally calling the operation.</p><section>
<h3><a name="rename.28.29"></a><code>rename()</code></h3>
<p>Avoid any algorithm which uploads data into a temporary file and then uses <code>rename()</code> to commit it into place with a final path. On HDFS this offers a fast commit operation. With S3, Wasb and other object stores, you can write straight to the destination, knowing that the file isn&#x2019;t visible until you close the write: the write itself is atomic.</p>
<p>The <code>rename()</code> operation may return <code>false</code> if the source is missing; this is a weakness in the API. Consider a check before calling rename, and if/when a new rename() call is made public, switch to it.</p></section><section>
<h3><a name="delete.28path.2C_recursive.29"></a><code>delete(path, recursive)</code></h3>
<p>Keep in mind that <code>delete(path, recursive)</code> is a no-op if the path does not exist, so there&#x2019;s no need to have a check for the path existing before you call it.</p>
<p><code>delete()</code> is often used as a cleanup operation. With an object store this is slow, and may cause problems if the caller expects an immediate response. For example, a thread may block so long that other liveness checks start to fail. Consider spawning off an executor thread to do these background cleanup operations.</p></section></section><section>
<h2><a name="Tuning_SSL_Performance"></a><a name="ssl"></a> Tuning SSL Performance</h2>
<p>By default, S3A uses HTTPS to communicate with AWS Services. This means that all communication with S3 is encrypted using SSL. The overhead of this encryption can significantly slow down applications. The configuration option <code>fs.s3a.ssl.channel.mode</code> allows applications to trigger certain SSL optimizations.</p>
<p>By default, <code>fs.s3a.ssl.channel.mode</code> is set to <code>default_jsse</code>, which uses the Java Secure Socket Extension implementation of SSL (this is the default implementation when running Java). However, there is one difference, the GCM cipher is removed from the list of enabled cipher suites when running on Java 8. The GCM cipher has known performance issues when running on Java 8, see HADOOP-15669 and HADOOP-16050 for details. It is important to note that the GCM cipher is only disabled on Java 8. GCM performance has been improved in Java 9, so if <code>default_jsse</code> is specified and applications run on Java 9, they should see no difference compared to running with the vanilla JSSE.</p>
<p><code>fs.s3a.ssl.channel.mode</code> can be set to <code>default_jsse_with_gcm</code>. This option includes GCM in the list of cipher suites on Java 8, so it is equivalent to running with the vanilla JSSE.</p><section>
<h3><a name="OpenSSL_Acceleration"></a><a name="openssl"></a> OpenSSL Acceleration</h3>
<p>As of HADOOP-16050 and HADOOP-16346, <code>fs.s3a.ssl.channel.mode</code> can be set to either <code>default</code> or <code>openssl</code> to enable native OpenSSL acceleration of HTTPS requests. OpenSSL implements the SSL and TLS protocols using native code. For users reading a large amount of data over HTTPS, OpenSSL can provide a significant performance benefit over the JSSE.</p>
<p>S3A uses the <a class="externalLink" href="https://github.com/wildfly-security/wildfly-openssl">WildFly OpenSSL</a> library to bind OpenSSL to the Java JSSE APIs. This library allows S3A to transparently read data using OpenSSL. The <code>wildfly-openssl</code> library is an optional runtime dependency of S3A and contains native libraries for binding the Java JSSE to OpenSSL.</p>
<p>WildFly OpenSSL must load OpenSSL itself. This can be done using the system property <code>org.wildfly.openssl.path</code>. For example, <code>HADOOP_OPTS=&quot;-Dorg.wildfly.openssl.path=&lt;path to OpenSSL libraries&gt; ${HADOOP_OPTS}&quot;</code>. See WildFly OpenSSL documentation for more details.</p>
<p>When <code>fs.s3a.ssl.channel.mode</code> is set to <code>default</code>, S3A will attempt to load the OpenSSL libraries using the WildFly library. If it is unsuccessful, it will fall back to the <code>default_jsse</code> behavior.</p>
<p>When <code>fs.s3a.ssl.channel.mode</code> is set to <code>openssl</code>, S3A will attempt to load the OpenSSL libraries using WildFly. If it is unsuccessful, it will throw an exception and S3A initialization will fail.</p></section><section>
<h3><a name="fs.s3a.ssl.channel.mode_Configuration"></a><code>fs.s3a.ssl.channel.mode</code> Configuration</h3>
<p><code>fs.s3a.ssl.channel.mode</code> can be configured as follows:</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.ssl.channel.mode&lt;/name&gt;
  &lt;value&gt;default_jsse&lt;/value&gt;
  &lt;description&gt;
    If secure connections to S3 are enabled, configures the SSL
    implementation used to encrypt connections to S3. Supported values are:
    &quot;default_jsse&quot;, &quot;default_jsse_with_gcm&quot;, &quot;default&quot;, and &quot;openssl&quot;.
    &quot;default_jsse&quot; uses the Java Secure Socket Extension package (JSSE).
    However, when running on Java 8, the GCM cipher is removed from the list
    of enabled ciphers. This is due to performance issues with GCM in Java 8.
    &quot;default_jsse_with_gcm&quot; uses the JSSE with the default list of cipher
    suites. &quot;default_jsse_with_gcm&quot; is equivalent to the behavior prior to
    this feature being introduced. &quot;default&quot; attempts to use OpenSSL rather
    than the JSSE for SSL encryption, if OpenSSL libraries cannot be loaded,
    it falls back to the &quot;default_jsse&quot; behavior. &quot;openssl&quot; attempts to use
    OpenSSL as well, but fails if OpenSSL libraries cannot be loaded.
  &lt;/description&gt;
&lt;/property&gt;
</pre></div></div>

<p>Supported values for <code>fs.s3a.ssl.channel.mode</code>:</p>
<table border="0" class="bodyTable">
<thead>

<tr class="a">
<th> <code>fs.s3a.ssl.channel.mode</code> Value </th>
<th> Description                                                            </th></tr>
</thead><tbody>

<tr class="b">
<td> <code>default_jsse</code>                  </td>
<td> Uses Java JSSE without GCM on Java 8                                   </td></tr>
<tr class="a">
<td> <code>default_jsse_with_gcm</code>         </td>
<td> Uses Java JSSE                                                         </td></tr>
<tr class="b">
<td> <code>default</code>                       </td>
<td> Uses OpenSSL, falls back to <code>default_jsse</code> if OpenSSL cannot be loaded </td></tr>
<tr class="a">
<td> <code>openssl</code>                       </td>
<td> Uses OpenSSL, fails if OpenSSL cannot be loaded                        </td></tr>
</tbody>
</table>
<p>The naming convention is setup in order to preserve backwards compatibility with the ABFS support of <a class="externalLink" href="https://issues.apache.org/jira/browse/HADOOP-15669">HADOOP-15669</a>.</p>
<p>Other options may be added to <code>fs.s3a.ssl.channel.mode</code> in the future as further SSL optimizations are made.</p></section><section>
<h3><a name="WildFly_classpath_and_SSL_library_requirements"></a>WildFly classpath and SSL library requirements</h3>
<p>For OpenSSL acceleration to work, a compatible version of the wildfly JAR must be on the classpath. This is not explicitly declared in the dependencies of the published <code>hadoop-aws</code> module, as it is optional.</p>
<p>If the wildfly JAR is not found, the network acceleration will fall back to the JVM, always.</p>
<p>Similarly, the <code>libssl</code> library must be compatibile with wildfly.</p>
<p>Wildfly requires this native library to be part of an <code>openssl</code> installation. Third party implementations may not work correctly. This can be an isse in FIPS-compliant deployments, where the <code>libssl</code> library is a third-party implementation built with restricted TLS protocols.</p>
<p>There have been compatibility problems with wildfly JARs and openSSL releases in the past: version 1.0.4.Final is not compatible with openssl 1.1.1. An extra complication was older versions of the <code>azure-data-lake-store-sdk</code> JAR used in <code>hadoop-azure-datalake</code> contained an unshaded copy of the 1.0.4.Final classes, causing binding problems even when a later version was explicitly being placed on the classpath.</p></section></section><section>
<h2><a name="Tuning_FileSystem_Initialization."></a><a name="initilization"></a> Tuning FileSystem Initialization.</h2><section>
<h3><a name="Bucket_existence_checks"></a>Bucket existence checks</h3>
<p>When an S3A Filesystem instance is created and initialized, the client can be checks if the bucket provided is valid. This can be slow, which is why it is disabled by default.</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.s3a.bucket.probe&lt;/name&gt;
  &lt;value&gt;0&lt;/value&gt;
&lt;/property&gt;
</pre></div></div>

<p>If the bucket does not exist, this issue will surface when operations are performed on the filesystem; you will see <code>UnknownStoreException</code> stack traces.</p>
<p>Re-enabling the probe will force an early check but but is generally not needed.</p></section><section>
<h3><a name="Rate_limiting_parallel_FileSystem_creation_operations"></a>Rate limiting parallel FileSystem creation operations</h3>
<p>Applications normally ask for filesystems from the shared cache, via <code>FileSystem.get()</code> or <code>Path.getFileSystem()</code>. The cache, <code>FileSystem.CACHE</code> will, for each user, cachec one instance of a filesystem for a given URI. All calls to <code>FileSystem.get</code> for a cached FS for a URI such as <code>s3a://noaa-isd-pds/</code> will return that singe single instance.</p>
<p>FileSystem instances are created on-demand for the cache, and will be done in each thread which requests an instance. This is done outside of any synchronisation block. Once a task has an initialized FileSystem instance, it will, in a synchronized block add it to the cache. If it turns out that the cache now already has an instance for that URI, it will revert the cached copy to it, and close the FS instance it has just created.</p>
<p>If a FileSystem takes time to be initialized, and many threads are trying to retrieve a FileSystem instance for the same S3 bucket in parallel, All but one of the threads will be doing useless work, and may unintentionally be creating lock contention on shared objects.</p>
<p>There is an option, <code>fs.creation.parallel.count</code>, which uses a semaphore to limit the number of FS instances which may be created in parallel.</p>
<p>Setting this to a low number will reduce the amount of wasted work, at the expense of limiting the number of FileSystem clients which can be created simultaneously for different object stores/distributed filesystems.</p>
<p>For example, a value of four would put an upper limit on the number of wasted instantiations of a connector for the <code>s3a://noaa-isd-pds/</code> bucket.</p>

<div class="source">
<div class="source">
<pre>&lt;property&gt;
  &lt;name&gt;fs.creation.parallel.count&lt;/name&gt;
  &lt;value&gt;4&lt;/value&gt;
&lt;/property&gt;
</pre></div></div>

<p>It would also mean that if four threads were in the process of creating such connectors, all threads trying to create connectors for other buckets, would end up blocking too.</p>
<p>Consider experimenting with this when running applications where many threads may try to simultaneously interact with the same slow-to-initialize object stores.</p></section></section>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">
        &#169;            2008-2024
              Apache Software Foundation
            
                          - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a>.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.
      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
