<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<head>
    <title>HBase</title>
</head>
<body bgcolor="white">
<a href="http://hbase.org">HBase</a> is a scalable, distributed database built on <a href="http://hadoop.apache.org/core">Hadoop Core</a>.

<h2><a name="requirements">Requirements</a></h2>
<ul>
  <li>Java 1.6.x, preferably from <a href="http://www.java.com/en/download/">Sun</a>.
  Use the latest version available.
  </li>
  <li>This version of HBase will only run on <a href="http://hadoop.apache.org/core/releases.html">Hadoop 0.20.x</a>.  
  </li>
  <li>
    ssh must be installed and sshd must be running to use Hadoop's
    scripts to manage remote Hadoop daemons.
  </li>
  <li>HBase currently is a file handle hog.  The usual default of
  1024 on *nix systems is insufficient if you are loading any significant
  amount of data into regionservers.  See the
  <a href="http://wiki.apache.org/hadoop/Hbase/FAQ#6">FAQ: Why do I see "java.io.IOException...(Too many open files)" in my logs?</a>
  for how to up the limit.  Also, as of 0.18.x hadoop, datanodes have an upper-bound
      on the number of threads they will support (<code>dfs.datanode.max.xcievers</code>).
      Default is 256.  If loading lots of data into hbase, up this limit on your
      hadoop cluster.
      <li>The clocks on cluster members should be in basic alignments.  Some skew is tolerable but
      wild skew can generate odd behaviors.  Run <a href="http://en.wikipedia.org/wiki/Network_Time_Protocol">NTP</a>
      on your cluster, or an equivalent.</li>
      <li>HBase depends on <a href="http://hadoop.apache.org/zookeeper/">ZooKeeper</a> as of release 0.20.0.
      In basic standalone and pseudo-distributed modes, HBase manages a ZooKeeper instance
      for you but it is required that you run a ZooKeeper Quorum when running HBase
      fully distributed (More on this below).
      </li>
      <li>This is a list of patches we recommend you apply to your running Hadoop cluster:
      <ul>
      <li><a hef="https://issues.apache.org/jira/browse/HADOOP-4681">HADOOP-4681 <i>"DFSClient block read failures cause open DFSInputStream to become unusable"</i></a>. This patch will help with the ever-popular, "No live nodes contain current block".
      The hadoop version bundled with hbase has this patch applied.  Its an HDFS client
      fix so this should do for usual usage but if your cluster is missing the patch,
      and in particular if calling hbase from a mapreduce job, you may run into this
      issue.
      </li>
      </ul>
      </li>
</ul>
<h3>Windows</h3>
If you are running HBase on Windows, you must install <a href="http://cygwin.com/">Cygwin</a>.
Additionally, it is <emph>strongly recommended</emph> that you add or append to the following
environment variables. If you install Cygwin in a location that is not <code>C:\cygwin</code> you
should modify the following appropriately.
<p>
<blockquote>
<pre>
HOME=c:\cygwin\home\jim
ANT_HOME=(wherever you installed ant)
JAVA_HOME=(wherever you installed java) 
PATH=C:\cygwin\bin;%JAVA_HOME%\bin;%ANT_HOME%\bin; other windows stuff 
SHELL=/bin/bash
</pre>
</blockquote>
For additional information, see the
<a href="http://hadoop.apache.org/core/docs/current/quickstart.html">Hadoop Quick Start Guide</a>
</p>
<h2><a name="getting_started" >Getting Started</a></h2>
<p>
What follows presumes you have obtained a copy of HBase,
see <a href="http://hadoop.apache.org/hbase/releases.html">Releases</a>, and are installing
for the first time. If upgrading your
HBase instance, see <a href="#upgrading">Upgrading</a>.
<p>Three modes are described: standalone, pseudo-distributed (where all servers are run on
a single host), and distributed.  If new to hbase start by following the standalone instruction.
</p>
<p>
Whatever your mode, define <code>${HBASE_HOME}</code> to be the location of the root of your HBase installation, e.g. 
<code>/user/local/hbase</code>.  Edit <code>${HBASE_HOME}/conf/hbase-env.sh</code>.  In this file you can
set the heapsize for HBase, etc.  At a minimum, set <code>JAVA_HOME</code> to point at the root of
your Java installation.
</p>
<h2><a name="standalone">Standalone Mode</a></h2>
<p>
If you are running a standalone operation, there should be nothing further to configure; proceed to
<a href=#runandconfirm>Running and Confirming Your Installation</a>.  If you are running a distributed 
operation, continue reading.
</p>

<h2><a name="distributed">Distributed Operation: Pseudo- and Fully-Distributed Modes</a></h2>
<p>Distributed mode requires an instance of the Hadoop Distributed File System (DFS).
See the Hadoop <a href="http://lucene.apache.org/hadoop/api/overview-summary.html#overview_description">
requirements and instructions</a> for how to set up a DFS.
</p>

<h3><a name="pseudo-distrib">Pseudo-Distributed Operation</a></h3>
<p>A pseudo-distributed operation is simply a distributed operation run on a single host.  
Once you have confirmed your DFS setup, configuring HBase for use on one host requires modification of 
<code>${HBASE_HOME}/conf/hbase-site.xml</code>, which needs to be pointed at the running Hadoop DFS instance.  
Use <code>hbase-site.xml</code> to override the properties defined in 
<code>${HBASE_HOME}/conf/hbase-default.xml</code> (<code>hbase-default.xml</code> itself 
should never be modified).  At a minimum the <code>hbase.rootdir</code> property should be redefined 
in <code>hbase-site.xml</code> to point HBase at the Hadoop filesystem to use.  For example, adding the property 
below to your <code>hbase-site.xml</code> says that HBase should use the <code>/hbase</code> directory in the 
HDFS whose namenode is at port 9000 on your local machine:
</p>
<pre>
&lt;configuration&gt;
  ...
  &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;
    &lt;description&gt;The directory shared by region servers.
    &lt;/description&gt;
  &lt;/property&gt;
  ...
&lt;/configuration&gt;
</pre>
<p>Note: Let hbase create the directory.  If you don't, you'll get warning saying hbase
needs a migration run because the directory is missing files expected by hbase (it'll
create them if you let it).
</p>

<h3><a name="fully-distrib">Fully-Distributed Operation</a></h3>
<p>For running a fully-distributed operation on more than one host, the following
configurations must be made <i>in addition</i> to those described in the
<a href="#pseudo-distrib">pseudo-distributed operation</a> section above.
In this mode, a ZooKeeper cluster is required.</p>  
<p>In <code>hbase-site.xml</code>, set <code>hbase.cluster.distributed</code> to 'true'. 
<blockquote>
<pre>
&lt;configuration&gt;
  ...
  &lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
    &lt;description&gt;The mode the cluster will be in. Possible values are
      false: standalone and pseudo-distributed setups with managed Zookeeper
      true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
    &lt;/description&gt;
  &lt;/property&gt;
  ...
&lt;/configuration&gt;
</pre>
</blockquote>
</p>
<p>
In fully-distributed operation, you probably want to change your <code>hbase.rootdir</code> 
from localhost to the name of the node running the HDFS namenode.  In addition
to <code>hbase-site.xml</code> changes, a fully-distributed operation requires that you 
modify <code>${HBASE_HOME}/conf/regionservers</code>.  
The <code>regionserver</code> file lists all hosts running HRegionServers, one host per line
(This file in HBase is like the hadoop slaves file at <code>${HADOOP_HOME}/conf/slaves</code>).
</p>
<p>
A distributed HBase depends on a running ZooKeeper cluster.
The ZooKeeper configuration file for HBase is stored at <code>${HBASE_HOME}/conf/zoo.cfg</code>.
See the ZooKeeper <a href="http://hadoop.apache.org/zookeeper/docs/current/zookeeperStarted.html"> Getting Started Guide</a>
for information about the format and options of that file.  Specifically, look at the 
<a href="http://hadoop.apache.org/zookeeper/docs/current/zookeeperStarted.html#sc_RunningReplicatedZooKeeper">Running Replicated ZooKeeper</a> section.


After configuring <code>zoo.cfg</code>, in <code>${HBASE_HOME}/conf/hbase-env.sh</code>,
set the following to tell HBase to STOP managing its instance of ZooKeeper.
<blockquote>
<pre>
  ...
# Tell HBase whether it should manage it's own instance of Zookeeper or not.
export HBASE_MANAGES_ZK=false
</pre>
</blockquote>
</p>
<p>
Though not recommended, it can be convenient having HBase continue to manage
ZooKeeper even when in distributed mode (It can be good when testing or taking
hbase for a testdrive).  Change <code>${HBASE_HOME}/conf/zoo.cfg</code> and
set the server.0 property to the IP of the node that will be running ZooKeeper
(Leaving the default value of "localhost" will make it impossible to start HBase).
<pre>
  ...
server.0=example.org:2888:3888
<blockquote>
</pre>
Then on the example.org server do the following <i>before</i> running HBase. 
<pre>
${HBASE_HOME}/bin/hbase-daemon.sh start zookeeper
</pre>
</blockquote>
<p>To stop ZooKeeper, after you've shut down hbase, do:
<blockquote>
<pre>
${HBASE_HOME}/bin/hbase-daemon.sh stop zookeeper
</pre>
</blockquote>
Be aware that this option is only recommanded for testing purposes as a failure
on that node would render HBase <b>unusable</b>.
</p>

<p>Of note, if you have made <i>HDFS client configuration</i> on your hadoop cluster, HBase will not
see this configuration unless you do one of the following:
<ul>
    <li>Add a pointer to your <code>HADOOP_CONF_DIR</code> to <code>CLASSPATH</code> in <code>hbase-env.sh</code></li>
    <li>Add a copy of <code>hadoop-site.xml</code> to <code>${HBASE_HOME}/conf</code>, or</li>
    <li>If only a small set of HDFS client configurations, add them to <code>hbase-site.xml</code></li>
</ul>
An example of such an HDFS client configuration is <code>dfs.replication</code>.  If for example,
you want to run with a replication factor of 5, hbase will create files with the default of 3 unless 
you do the above to make the configuration available to HBase.
</p>

<h2><a name="runandconfirm">Running and Confirming Your Installation</a></h2>
<p>If you are running in standalone, non-distributed mode, HBase by default uses
the local filesystem.</p>

<p>If you are running a distributed cluster you will need to start the Hadoop DFS daemons and
ZooKeeper Quorum
before starting HBase and stop the daemons after HBase has shut down.</p>
<p>Start and 
stop the Hadoop DFS daemons by running <code>${HADOOP_HOME}/bin/start-dfs.sh</code>.
You can ensure it started properly by testing the put and get of files into the Hadoop filesystem.
HBase does not normally use the mapreduce daemons.  These do not need to be started.</p>

<p>Start up your ZooKeeper cluster.</p>

<p>Start HBase with the following command:
</p>
<pre>
${HBASE_HOME}/bin/start-hbase.sh
</pre>
<p>
Once HBase has started, enter <code>${HBASE_HOME}/bin/hbase shell</code> to obtain a 
shell against HBase from which you can execute commands.  
Test your installation by creating, viewing, and dropping 
To stop HBase, exit the HBase shell and enter:
</p>
<pre>
${HBASE_HOME}/bin/stop-hbase.sh
</pre>
<p>
If you are running a distributed operation, be sure to wait until HBase has shut down completely 
before stopping the Hadoop daemons.
</p>
<p>
The default location for logs is <code>${HBASE_HOME}/logs</code>.
</p>
<p>HBase also puts up a UI listing vital attributes.  By default its deployed on the master host
at port 60010 (HBase regionservers listen on port 60020 by default and put up an informational
http server at 60030).</p>

<h2><a name="upgrading" >Upgrading</a></h2>
<p>After installing a new HBase on top of data written by a previous HBase version, before
starting your cluster, run the <code>${HBASE_DIR}/bin/hbase migrate</code> migration script.
It will make any adjustments to the filesystem data under <code>hbase.rootdir</code> necessary to run
the HBase version. It does not change your install unless you explicitly ask it to.
</p>

<h2><a name="client_example">Example API Usage</a></h2>
For sample Java code, see <a href="org/apache/hadoop/hbase/client/package-summary.html#client_example">org.apache.hadoop.hbase.client</a> documentation.

<p>If your client is NOT Java, consider the Thrift or REST libraries.</p>

<h2><a name="related" >Related Documentation</a></h2>
<ul>
  <li><a href="http://hbase.org">HBase Home Page</a>
  <li><a href="http://wiki.apache.org/hadoop/Hbase">HBase Wiki</a>
  <li><a href="http://hadoop.apache.org/">Hadoop Home Page</a>
</ul>

</body>
</html>
