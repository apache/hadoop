<?xml version="1.0"?>

<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<project name="Hadoop-Hdfs" default="compile" 
   xmlns:artifact="urn:maven-artifact-ant"
   xmlns:ivy="antlib:org.apache.ivy.ant"> 

  <!-- Load all the default properties, and any the user wants    -->
  <!-- to contribute (without having to type -D or edit this file -->
  <property file="${user.home}/build.properties" />
  <property file="${basedir}/build.properties" />
 
  <property name="Name" value="Hadoop-Hdfs"/>
  <property name="name" value="hadoop-hdfs"/>
  <property name="version" value="0.21.0-SNAPSHOT"/>
  <property name="final.name" value="${name}-${version}"/>
  <property name="test.hdfs.final.name" value="${name}-test-${version}"/>
  <property name="ant.final.name" value="${name}-ant-${version}"/>
  <property name="year" value="2009"/>

  <property name="src.dir" value="${basedir}/src"/>  	
  <property name="java.src.dir" value="${src.dir}/java"/>
  <property name="anttasks.dir" value="${basedir}/src/ant"/>
  <property name="lib.dir" value="${basedir}/lib"/>
  <property name="conf.dir" value="${basedir}/conf"/>
  <property name="contrib.dir" value="${basedir}/src/contrib"/>
  <property name="docs.src" value="${basedir}/src/docs"/>
  <property name="changes.src" value="${docs.src}/changes"/>

  <property name="build.dir" value="${basedir}/build"/>
  <property name="build-fi.dir" value="${basedir}/build-fi"/>
  <property name="build.classes" value="${build.dir}/classes"/>
  <property name="build.src" value="${build.dir}/src"/>
  <property name="build.webapps" value="${build.dir}/webapps"/>
  <property name="build.anttasks" value="${build.dir}/ant"/>
  <!-- convert spaces to _ so that mac os doesn't break things -->
  <exec executable="sed" inputstring="${os.name}" 
        outputproperty="nonspace.os">
     <arg value="s/ /_/g"/>
  </exec>
  <property name="build.platform" 
            value="${nonspace.os}-${os.arch}-${sun.arch.data.model}"/>
  <property name="jvm.arch" 
            value="${sun.arch.data.model}"/>

  <property name="build.docs" value="${build.dir}/docs"/>
  <property name="build.javadoc" value="${build.docs}/api"/>
  <property name="build.javadoc.timestamp" value="${build.javadoc}/index.html" />
  <property name="build.javadoc.dev" value="${build.docs}/dev-api"/>
  <property name="build.encoding" value="ISO-8859-1"/>

  <property name="test.src.dir" value="${basedir}/src/test"/>
  <property name="test.lib.dir" value="${basedir}/src/test/lib"/>
  <property name="test.build.dir" value="${build.dir}/test"/>
  <property name="test.generated.dir" value="${test.build.dir}/src"/>
  <property name="test.build.data" value="${test.build.dir}/data"/>
  <property name="test.cache.data" value="${test.build.dir}/cache"/>
  <property name="test.debug.data" value="${test.build.dir}/debug"/>
  <property name="test.log.dir" value="${test.build.dir}/logs"/>
  <property name="test.build.classes" value="${test.build.dir}/classes"/>
  <property name="test.build.extraconf" value="${test.build.dir}/extraconf"/>
  <property name="test.build.javadoc" value="${test.build.dir}/docs/api"/>
  <property name="test.build.javadoc.dev" value="${test.build.dir}/docs/dev-api"/>
  <property name="test.include" value="Test*"/>
  <property name="test.classpath.id" value="test.classpath"/>
  <property name="test.output" value="no"/>
  <property name="test.timeout" value="900000"/>
  <property name="test.junit.output.format" value="plain"/>
  <property name="test.junit.fork.mode" value="perTest" />
  <property name="test.junit.printsummary" value="yes" />
  <property name="test.junit.haltonfailure" value="no" />
  <property name="test.junit.maxmemory" value="512m" />

  <property name="test.hdfs.build.classes" value="${test.build.dir}/classes"/>

  <property name="test.hdfs.commit.tests.file" value="${test.src.dir}/commit-tests" />
  <property name="test.hdfs.all.tests.file" value="${test.src.dir}/all-tests" />

  <property name="web.src.dir" value="${basedir}/src/web"/>
  <property name="src.webapps" value="${basedir}/src/webapps"/>

  <property name="javadoc.link.java"
	    value="http://java.sun.com/javase/6/docs/api/"/>
  <property name="javadoc.packages" value="org.apache.hadoop.*"/>
  <property name="javadoc.maxmemory" value="512m" />

  <property name="dist.dir" value="${build.dir}/${final.name}"/>

  <property name="javac.debug" value="on"/>
  <property name="javac.optimize" value="on"/>
  <property name="javac.deprecation" value="off"/>
  <property name="javac.version" value="1.6"/>
  <property name="javac.args" value=""/>
  <property name="javac.args.warnings" value="-Xlint:unchecked"/>

  <property name="clover.db.dir" location="${build.dir}/test/clover/db"/>
  <property name="clover.report.dir" location="${build.dir}/test/clover/reports"/>

  <property name="rat.reporting.classname" value="rat.Report"/>

  <property name="jdiff.build.dir" value="${build.docs}/jdiff"/>
  <property name="jdiff.xml.dir" value="${lib.dir}/jdiff"/>
  <property name="jdiff.stable" value="0.20.0"/>
  <property name="jdiff.stable.javadoc" 
            value="http://hadoop.apache.org/hdfs/docs/r${jdiff.stable}/api/"/>

  <property name="scratch.dir" value="${user.home}/tmp"/>
  <property name="svn.cmd" value="svn"/>
  <property name="grep.cmd" value="grep"/>
  <property name="patch.cmd" value="patch"/>
  <property name="make.cmd" value="make"/>
	
  <!-- IVY properties set here -->
  <property name="ivy.dir" location="ivy" />
  <loadproperties srcfile="${ivy.dir}/libraries.properties"/>
  <property name="ivy.jar" location="${ivy.dir}/ivy-${ivy.version}.jar"/>
  <property name="mvn.repo" value="http://repo2.maven.org/maven2"/>
  <property name="ivy_repo_url" value="${mvn.repo}/org/apache/ivy/ivy/${ivy.version}/ivy-${ivy.version}.jar"/>
  <property name="ant_task.jar" location="${ivy.dir}/maven-ant-tasks-${ant-task.version}.jar"/>
  <property name="ant_task_repo_url" value="${mvn.repo}/org/apache/maven/maven-ant-tasks/${ant-task.version}/maven-ant-tasks-${ant-task.version}.jar"/>
  <property name="ivysettings.xml" location="${ivy.dir}/ivysettings.xml" />
  <property name="ivy.org" value="org.apache.hadoop"/>
  <property name="build.dir" location="build" />
  <property name="dist.dir" value="${build.dir}/${final.name}"/>
  <property name="build.ivy.dir" location="${build.dir}/ivy" />
  <property name="build.ivy.lib.dir" location="${build.ivy.dir}/lib" />
  <property name="common.ivy.lib.dir" location="${build.ivy.lib.dir}/${ant.project.name}/common"/>
  <property name="test.ivy.lib.dir" location="${build.ivy.lib.dir}/${ant.project.name}/test"/>
  <property name="build.ivy.report.dir" location="${build.ivy.dir}/report" />
  <property name="build.ivy.maven.dir" location="${build.ivy.dir}/maven" />
  <property name="build.ivy.maven.pom" location="${build.ivy.maven.dir}/hadoop-hdfs-${version}.pom" />
  <property name="build.ivy.maven.jar" location="${build.ivy.maven.dir}/hadoop-hdfs-${version}.jar" />
  <property name="hadoop-hdfs.pom" location="${ivy.dir}/hadoop-hdfs.xml"/>
  <property name="hadoop-hdfs-test.pom" location="${ivy.dir}/hadoop-hdfs-test.xml"/>

  <!--this is the naming policy for artifacts we want pulled down-->
  <property name="ivy.artifact.retrieve.pattern" value="${ant.project.name}/[conf]/[artifact]-[revision].[ext]"/>

  <!--this is how artifacts that get built are named-->
  <property name="ivy.publish.pattern" value="hadoop-hdfs-[revision].[ext]"/>
  <property name="hadoop-hdfs.jar" location="${build.dir}/${final.name}.jar" />
  <property name="hadoop-hdfs-test.jar" location="${build.dir}/${test.hdfs.final.name}.jar" />
  <property name="hadoop-hdfs-fi.jar" location="${build.dir}/${final.name}-fi.jar" />

  <!-- jdiff.home property set -->
  <property name="jdiff.home" value="${build.ivy.lib.dir}/${ant.project.name}/jdiff"/>
  <property name="jdiff.jar" value="${jdiff.home}/jdiff-${jdiff.version}.jar"/>
  <property name="xerces.jar" value="${jdiff.home}/xerces-${xerces.version}.jar"/>

  <property name="clover.jar" location="${clover.home}/lib/clover.jar"/>
  <available property="clover.present" file="${clover.jar}" />

  <!-- check if clover reports should be generated -->
  <condition property="clover.enabled">
    <and>
        <isset property="run.clover"/>
        <isset property="clover.present"/>
    </and>
  </condition>

  <!-- the normal classpath -->
  <path id="classpath">
    <pathelement location="${build.classes}"/>
    <pathelement location="${conf.dir}"/>
    <path refid="ivy-common.classpath"/>
  </path>

  <path id="test.classpath">
    <pathelement location="${test.build.extraconf}"/>
    <pathelement location="${test.hdfs.build.classes}" />
    <pathelement location="${test.src.dir}"/>
    <pathelement location="${build.dir}"/>
    <pathelement location="${build.tools}"/>
    <pathelement path="${clover.jar}"/>
    <path refid="ivy-test.classpath"/>
    <fileset dir="${lib.dir}">
      <include name="hadoop-core-test-${hadoop-core.version}.jar" />
      <exclude name="**/excluded/" />
    </fileset>
    <path refid="classpath"/>
  </path>

  <!-- the cluster test classpath: uses conf.dir for configuration -->
  <path id="test.cluster.classpath">
    <path refid="classpath"/>
    <pathelement location="${test.build.classes}" />
    <pathelement location="${test.src.dir}"/>
    <pathelement location="${build.dir}"/>
  </path>


  <!-- ====================================================== -->
  <!-- Macro definitions                                      -->
  <!-- ====================================================== -->
  <macrodef name="macro_tar" description="Worker Macro for tar">
    <attribute name="param.destfile"/>
    <element name="param.listofitems"/>
    <sequential>
      <tar compression="gzip" longfile="gnu"
      destfile="@{param.destfile}">
      <param.listofitems/>
      </tar>
    </sequential>
  </macrodef>

  <!-- ====================================================== -->
  <!-- Stuff needed by all targets                            -->
  <!-- ====================================================== -->
  <target name="init" depends="ivy-retrieve-common">
    <mkdir dir="${build.dir}"/>
    <mkdir dir="${build.classes}"/>
    <mkdir dir="${build.src}"/>
    <mkdir dir="${build.webapps}/hdfs/WEB-INF"/>
    <mkdir dir="${build.webapps}/datanode/WEB-INF"/>
    <mkdir dir="${build.webapps}/secondary/WEB-INF"/>
    <mkdir dir="${build.anttasks}"/>
 
    <mkdir dir="${test.build.dir}"/>
    <mkdir dir="${test.build.classes}"/>
    <mkdir dir="${test.build.extraconf}"/>
    <tempfile property="touch.temp.file" destDir="${java.io.tmpdir}"/>
    <touch millis="0" file="${touch.temp.file}">
      <fileset dir="${conf.dir}" includes="**/*.template"/>
      <fileset dir="${contrib.dir}" includes="**/*.template"/>
    </touch>
    <delete file="${touch.temp.file}"/>
    <!-- copy all of the jsp and static files -->
    <copy todir="${build.webapps}">
      <fileset dir="${src.webapps}">
        <exclude name="**/*.jsp" />
      </fileset>
    </copy>

    <copy todir="${conf.dir}" verbose="true">
      <fileset dir="${conf.dir}" includes="**/*.template"/>
      <mapper type="glob" from="*.template" to="*"/>
    </copy>

    <copy todir="${contrib.dir}" verbose="true">
      <fileset dir="${contrib.dir}" includes="**/*.template"/>
      <mapper type="glob" from="*.template" to="*"/>
    </copy>

  </target>

  <target name="compile-hdfs-classes" depends="init">
    <taskdef classname="org.apache.jasper.JspC" name="jsp-compile" >
       <classpath refid="classpath"/>
    </taskdef>
    <jsp-compile
     uriroot="${src.webapps}/hdfs"
     outputdir="${build.src}"
     package="org.apache.hadoop.hdfs.server.namenode"
     webxml="${build.webapps}/hdfs/WEB-INF/web.xml">
    </jsp-compile>

    <jsp-compile
     uriroot="${src.webapps}/datanode"
     outputdir="${build.src}"
     package="org.apache.hadoop.hdfs.server.datanode"
     webxml="${build.webapps}/datanode/WEB-INF/web.xml">
    </jsp-compile>

    <jsp-compile
     uriroot="${src.webapps}/secondary"
     outputdir="${build.src}"
     package="org.apache.hadoop.hdfs.server.namenode"
     webxml="${build.webapps}/secondary/WEB-INF/web.xml">
    </jsp-compile>

    <!-- Compile Java files (excluding JSPs) checking warnings -->
    <javac 
     encoding="${build.encoding}" 
     srcdir="${java.src.dir};${build.src}" 
     includes="org/apache/hadoop/**/*.java"
     destdir="${build.classes}"
     debug="${javac.debug}"
     optimize="${javac.optimize}"
     target="${javac.version}"
     source="${javac.version}"
     deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath refid="classpath"/>
    </javac>   

    <copy todir="${build.classes}">
     <fileset dir="${java.src.dir}" includes="**/*.properties"/>
     <fileset dir="${java.src.dir}" includes="hdfs-default.xml"/>
    </copy>
  </target>

  <!--All Fault Injection (FI) related targets are located in this session -->
  
  <!-- Weaving aspects in place
  	Later on one can run 'ant jar-fault-inject' to create
  	Hadoop jar file with instrumented classes
  -->
  <property name="compile-inject.output" value="${build-fi.dir}/compile-fi.log"/>
  <target name="compile-fault-inject" depends="compile-core, compile-hdfs-test">
    <!-- AspectJ task definition -->
    <taskdef
        resource="org/aspectj/tools/ant/taskdefs/aspectjTaskdefs.properties">
      <classpath>
        <pathelement location="${common.ivy.lib.dir}/aspectjtools-1.6.5.jar"/>
      </classpath>
    </taskdef>
    <echo message="Start weaving aspects in place"/>
    <iajc
      encoding="${build.encoding}" 
      srcdir="${java.src.dir};${build.src};${test.src.dir}/aop" 
      includes="org/apache/hadoop/**/*.java, org/apache/hadoop/**/*.aj"
      destDir="${build.classes}"
      debug="${javac.debug}"
      target="${javac.version}"
      source="${javac.version}"
      deprecation="${javac.deprecation}">
      <classpath refid="test.classpath"/>
    </iajc>
    <loadfile property="injection.failure" srcfile="${compile-inject.output}">
      <filterchain>
        <linecontainsregexp>
          <regexp pattern='iajc.*warning'/>
        </linecontainsregexp>
      </filterchain>
    </loadfile>
    <fail if="injection.failure">
      Broken binding of advises: ${line.separator}${injection.failure}
    </fail>
    <echo message="Weaving of aspects is finished"/>
  </target>

  <target name="injectfaults"
          description="Instrument HDFS classes with faults and other AOP advices">
    <!--mkdir to prevent <subant> failure in case the folder has been removed-->
    <mkdir dir="${build-fi.dir}"/>
    <delete file="${compile-inject.output}"/>
    <subant buildpath="${basedir}" target="compile-fault-inject"
            output="${compile-inject.output}">
      <property name="build.dir" value="${build-fi.dir}"/>
    </subant>
  </target>

  <!--At this moment there's no special FI test suite thus the normal tests are -->
  <!--being executed with faults injected in place-->

  <!--This target is not included into the the top level list of target
  for it serves a special "regression" testing purpose of non-FI tests in
  FI environment -->
  <target name="run-with-fault-inject-testcaseonly">
    <fail unless="testcase">Can't run this target without -Dtestcase setting!
    </fail>
    <subant buildpath="build.xml" target="run-test-hdfs-fault-inject">
    	<property name="special.fi.testcasesonly" value="yes"/>
    </subant>
  </target>

  <target name="run-test-hdfs-fault-inject" depends="injectfaults"
          description="Run Fault Injection related hdfs tests">
    <subant buildpath="build.xml" target="run-test-hdfs">
      <property name="build.dir" value="${build-fi.dir}"/>
      <property name="test.fault.inject" value="yes"/>
      <property name="test.include" value="TestFi*"/>
    </subant>
  </target>

  <!-- ================================================================== -->
  <!-- Make hadoop-fi.jar including all Fault Iinjected artifacts         -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="jar-fault-inject" description="Make hadoop-fi.jar">
    <subant buildpath="build.xml" target="create-jar-fault-inject">
      <property name="build.dir" value="${build-fi.dir}"/>
    </subant>
  </target>

  <target name="create-jar-fault-inject" depends="injectfaults">
    <jar jarfile="${hadoop-hdfs-fi.jar}"
         basedir="${build.classes}">
      <manifest>
        <section name="org/apache/hadoop">
          <attribute name="Implementation-Title" value="${ant.project.name}"/>
          <attribute name="Implementation-Version" value="${version}"/>
          <attribute name="Implementation-Vendor" value="Apache"/>
        </section>
      </manifest>
      <fileset file="${conf.dir}/commons-logging.properties"/>
      <fileset file="${conf.dir}/log4j.properties"/>
      <fileset file="${conf.dir}/hadoop-metrics.properties"/>
      <fileset file="${test.src.dir}/fi-site.xml"/>
      <zipfileset dir="${build.webapps}" prefix="webapps"/>
    </jar>
  </target>

  <!-- ================================================================== -->
  <!-- Make test jar files including all Fault Injected artifacts         -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->

  <target name="jar-test-fault-inject" depends="jar-hdfs-test-fault-inject"
          description="Make hadoop-test.jar files"/>

  <target name="jar-hdfs-test-fault-inject" description="Make hadoop-test-fi.jar">
    <subant buildpath="build.xml" target="jar-hdfs-test">
      <property name="build.dir" value="${build-fi.dir}"/>
      <property name="test.hdfs.final.name" value="${name}-test-${version}-fi"/>
    </subant>
  </target>

  <!--End of Fault Injection (FI) related session-->

  <target name="compile-core" depends="clover, compile-hdfs-classes" description="Compile"/> 

  <target name="compile-contrib" depends="compile-core">
     <subant target="compile">
        <property name="version" value="${version}"/>
        <fileset file="${contrib.dir}/build.xml"/>
     </subant>  	
  </target>
  
  <target name="compile" depends="compile-core, compile-contrib, compile-ant-tasks" description="Compile core, contrib"/>

  <!-- ================================================================== -->
  <!-- Make hadoop.jar                                                     -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="jar" depends="compile-core" description="Make hadoop.jar">
    <jar jarfile="${hadoop-hdfs.jar}"
         basedir="${build.classes}">
      <manifest>
        <section name="org/apache/hadoop">
          <attribute name="Implementation-Title" value="${ant.project.name}"/>
          <attribute name="Implementation-Version" value="${version}"/>
          <attribute name="Implementation-Vendor" value="Apache"/>
        </section>
      </manifest>
      <fileset file="${conf.dir}/commons-logging.properties"/>
      <fileset file="${conf.dir}/log4j.properties"/>
      <fileset file="${conf.dir}/hadoop-metrics.properties"/>
      <zipfileset dir="${build.webapps}" prefix="webapps"/>
    </jar>
  </target>

  <target name="compile-hdfs-test" depends="compile-hdfs-classes, ivy-retrieve-test">
    <mkdir dir="${test.hdfs.build.classes}"/>
    <javac 
      encoding="${build.encoding}" 
      srcdir="${test.src.dir}/hdfs;${test.src.dir}/unit"
      includes="org/apache/hadoop/**/*.java"
      destdir="${test.hdfs.build.classes}"
      debug="${javac.debug}"
      optimize="${javac.optimize}"
      target="${javac.version}"
      source="${javac.version}"
      deprecation="${javac.deprecation}">
      <compilerarg line="${javac.args} ${javac.args.warnings}" />
      <classpath refid="test.classpath"/>
    </javac>

    <delete dir="${test.cache.data}"/>
    <mkdir dir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/hdfs/hadoop-14-dfs-dir.tgz" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/hdfs/hadoop-dfs-dir.txt" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/cli/testHDFSConf.xml" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/cli/clitest_data/data15bytes" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/cli/clitest_data/data30bytes" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/cli/clitest_data/data60bytes" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/cli/clitest_data/data120bytes" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/cli/clitest_data/data1k" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/hdfs/tools/offlineImageViewer/fsimageV18" todir="${test.cache.data}"/>
    <copy file="${test.src.dir}/hdfs/org/apache/hadoop/hdfs/tools/offlineImageViewer/fsimageV19" todir="${test.cache.data}"/>
  </target>

  <!-- ================================================================== -->
  <!-- Make hadoop-test.jar                                               -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="jar-test" depends="jar-hdfs-test" description="Make hadoop-test.jar"/> 

  <target name="jar-hdfs-test" depends="compile-hdfs-test" description="Make hadoop-hdfs-test.jar">
    <copy todir="${test.build.classes}">
      <fileset dir="${test.hdfs.build.classes}"/>
    </copy>
    <jar jarfile="${build.dir}/${test.hdfs.final.name}.jar"
         basedir="${test.build.classes}">
         <manifest>
           <attribute name="Main-Class"
                      value="org/apache/hadoop/test/HdfsTestDriver"/>
          <section name="org/apache/hadoop">
            <attribute name="Implementation-Title" value="${ant.project.name}"/>
            <attribute name="Implementation-Version" value="${version}"/>
            <attribute name="Implementation-Vendor" value="Apache"/>
          </section>
         </manifest>
    </jar>
  </target>

  <condition property="tests.notestcase">
    <and>
      <isfalse value="${test.fault.inject}"/>
      <not>
        <isset property="testcase"/>
      </not>
    </and>
  </condition>
  <condition property="tests.notestcase.fi">
    <and>
      <not>
        <isset property="testcase" />
      </not>
      <istrue value="${test.fault.inject}" />
    </and>
  </condition>
  <condition property="tests.testcase">
    <and>
      <isfalse value="${test.fault.inject}" />
      <isset property="testcase" />
    </and>
  </condition>
  <condition property="tests.testcase.fi">
    <and>
      <istrue value="${test.fault.inject}" />
      <isset property="testcase" />
    </and>
  </condition>

  <!-- ================================================================== -->
  <!-- Run unit tests                                                     --> 
  <!-- ================================================================== -->
  <macrodef name="macro-test-runner">
    <attribute name="test.file" />
    <attribute name="suite.type" />
    <sequential>
      <delete dir="${test.build.data}"/>
      <mkdir dir="${test.build.data}"/>
      <delete dir="${test.log.dir}"/>
      <mkdir dir="${test.log.dir}"/>
      <copy file="${test.src.dir}/hadoop-policy.xml" 
        todir="${test.build.extraconf}" />
      <copy file="${test.src.dir}/fi-site.xml"
        todir="${test.build.extraconf}" />
      <junit showoutput="${test.output}"
        printsummary="${test.junit.printsummary}"
        haltonfailure="${test.junit.haltonfailure}"
        fork="yes"
        forkmode="${test.junit.fork.mode}"
        maxmemory="${test.junit.maxmemory}"
        dir="${basedir}" timeout="${test.timeout}"
        errorProperty="tests.failed" failureProperty="tests.failed">
        <sysproperty key="test.build.data" value="${test.build.data}"/>
        <sysproperty key="test.cache.data" value="${test.cache.data}"/>     
        <sysproperty key="test.debug.data" value="${test.debug.data}"/>
        <sysproperty key="hadoop.log.dir" value="${test.log.dir}"/>
        <sysproperty key="test.src.dir" value="${test.src.dir}"/>
        <sysproperty key="test.build.extraconf" value="${test.build.extraconf}" />
        <sysproperty key="hadoop.policy.file" value="hadoop-policy.xml"/>
        <classpath refid="test.classpath"/>
        <!-- Pass probability specifications to the spawn JVM -->
        <syspropertyset id="FaultProbabilityProperties">
          <propertyref regex="fi.*"/>
        </syspropertyset>
        <formatter type="${test.junit.output.format}" />
        <batchtest todir="${test.build.dir}" if="tests.notestcase">
          <fileset dir="${test.src.dir}/@{suite.type}" excludes="**/${test.exclude}.java">
             <patternset>
               <includesfile name="@{test.file}"/>
             </patternset>
         </fileset>
        </batchtest>
        <batchtest todir="${test.build.dir}" if="tests.notestcase.fi">
          <fileset dir="${test.src.dir}/aop"
            includes="**/${test.include}.java"
            excludes="**/${test.exclude}.java" />
        </batchtest>
        <batchtest todir="${test.build.dir}" if="tests.testcase">
          <fileset dir="${test.src.dir}/@{suite.type}" includes="**/${testcase}.java"/>
        </batchtest>
        <batchtest todir="${test.build.dir}" if="tests.testcase.fi">
          <fileset dir="${test.src.dir}/aop" includes="**/${testcase}.java"/>
        </batchtest>
        <!--The following batch is for very special occasions only when
        a non-FI tests are needed to be executed against FI-environment -->
        <batchtest todir="${test.build.dir}" if="special.fi.testcasesonly">
          <fileset dir="${test.src.dir}/aop" includes="**/${testcase}.java"/>
          <fileset dir="${test.src.dir}/hdfs" includes="**/${testcase}.java"/>
        </batchtest>
      </junit>
      <antcall target="checkfailure"/>
    </sequential>
  </macrodef>

  <target name="run-test-hdfs" depends="compile-hdfs-test" description="Run full set of hdfs unit tests">
    <macro-test-runner test.file="${test.hdfs.all.tests.file}" suite.type="hdfs"/>
  </target>

  <target name="run-commit-test" depends="compile-hdfs-test" description="Run approximate 10-minute set of unit tests prior to commiting">
     <macro-test-runner test.file="${test.hdfs.commit.tests.file}" suite.type="hdfs"/>
  </target>

  <target name="run-test-unit" depends="compile-hdfs-test" description="Run unit tests">
    <macro-test-runner test.file="${test.hdfs.all.tests.file}" suite.type="unit"/>
  </target>

  <target name="checkfailure" if="tests.failed">
    <touch file="${test.build.dir}/testsfailed"/>
    <fail unless="continueOnFailure">Tests failed!</fail>
  </target>

  <target name="test-contrib" depends="compile-hdfs-test" description="Run contrib unit tests">
    <subant target="test">
       <property name="version" value="${version}"/>
       <property name="hadoop-version" value="${hadoop-core.version}"/>
       <property name="clover.jar" value="${clover.jar}"/>
       <fileset file="${contrib.dir}/build.xml"/>
    </subant> 
  </target> 

  <target name="test-core" description="Run hdfs unit tests">
    <delete file="${test.build.dir}/testsfailed"/>
    <property name="continueOnFailure" value="true"/>
    <antcall target="run-test-hdfs"/>
    <antcall target="run-test-unit"/>
    <antcall target="run-test-hdfs-fault-inject"/>
    <available file="${test.build.dir}/testsfailed" property="testsfailed"/>
    <fail if="testsfailed">Tests failed!</fail>
  </target>

  <target name="test" depends="jar-test, test-core" description="Run all unit tests">
    <subant target="test-contrib">
      <fileset file="${basedir}/build.xml"/>
     </subant>
  </target>

  <!-- Run all unit tests, not just Test*, and use non-test configuration. -->
  <target name="test-cluster" description="Run all unit tests, not just Test*, and use non-test configuration.">
    <antcall target="test">
      <param name="test.include" value="*"/>
      <param name="test.classpath.id" value="test.cluster.classpath"/>
    </antcall>
  </target>

  <target name="nightly" depends="test, tar">
  </target>
	
  <!-- ================================================================== -->
  <!-- Run optional third-party tool targets                              --> 
  <!-- ================================================================== -->
  <target name="checkstyle" depends="ivy-retrieve-checkstyle,check-for-checkstyle" if="checkstyle.present" description="Run optional third-party tool targets">
       <taskdef resource="checkstyletask.properties">
         <classpath refid="checkstyle-classpath"/>
       </taskdef>
  
	<mkdir dir="${test.build.dir}"/>
  	
  	<checkstyle config="${test.src.dir}/checkstyle.xml"
  		failOnViolation="false">
      <fileset dir="${java.src.dir}" includes="**/*.java" excludes="**/generated/**"/>  		
      <formatter type="xml" toFile="${test.build.dir}/checkstyle-errors.xml"/>
  	</checkstyle>
  	
  	<xslt style="${test.src.dir}/checkstyle-noframes-sorted.xsl"
        in="${test.build.dir}/checkstyle-errors.xml"
        out="${test.build.dir}/checkstyle-errors.html"/>
  </target>
	
  <target name="check-for-checkstyle">
    <available property="checkstyle.present" resource="checkstyletask.properties">
       <classpath refid="checkstyle-classpath"/>
    </available>  	
  </target>

 <property name="findbugs.home" value=""/>
  <target name="findbugs" depends="check-for-findbugs, jar" if="findbugs.present" description="Run findbugs if present">
    <property name="findbugs.out.dir" value="${test.build.dir}/findbugs"/>
    <property name="findbugs.exclude.file" value="${test.src.dir}/findbugsExcludeFile.xml"/>
    <property name="findbugs.report.htmlfile" value="${findbugs.out.dir}/hadoop-findbugs-report.html"/>
    <property name="findbugs.report.xmlfile" value="${findbugs.out.dir}/hadoop-findbugs-report.xml"/>
    <taskdef name="findbugs" classname="edu.umd.cs.findbugs.anttask.FindBugsTask"
        classpath="${findbugs.home}/lib/findbugs-ant.jar" />

        <mkdir dir="${findbugs.out.dir}"/>

    <findbugs home="${findbugs.home}" output="xml:withMessages"
        outputFile="${findbugs.report.xmlfile}" effort="max"
        excludeFilter="${findbugs.exclude.file}" jvmargs="-Xmx512M">
      <auxClasspath>
        <fileset dir="${lib.dir}">
          <include name="**/*.jar"/>
        </fileset>
        <fileset dir="${build.ivy.lib.dir}/${ant.project.name}/common">
          <include name="**/*.jar"/>
        </fileset>
      </auxClasspath>
      <sourcePath path="${java.src.dir}"/>
      <class location="${basedir}/build/${final.name}.jar" />
    </findbugs>

        <xslt style="${findbugs.home}/src/xsl/default.xsl"
        in="${findbugs.report.xmlfile}"
        out="${findbugs.report.htmlfile}"/>
  </target>
	
  <target name="check-for-findbugs">
    <available property="findbugs.present"
        file="${findbugs.home}/lib/findbugs.jar" />
  </target>


  <!-- ================================================================== -->
  <!-- Documentation                                                      -->
  <!-- ================================================================== -->
  
  <target name="docs" depends="forrest.check" description="Generate forrest-based documentation. To use, specify -Dforrest.home=&lt;base of Apache Forrest installation&gt; on the command line." if="forrest.home">
    <exec dir="${docs.src}" executable="${forrest.home}/bin/forrest"
	  failonerror="true">
      <env key="JAVA_HOME" value="${java5.home}"/>
    </exec>
    <copy todir="${build.docs}">
      <fileset dir="${docs.src}/build/site/" />
    </copy>
    <copy file="${docs.src}/releasenotes.html" todir="${build.docs}"/>
    <style basedir="${java.src.dir}" destdir="${build.docs}"
           includes="hdfs-default.xml" style="conf/configuration.xsl"/>
    <antcall target="changes-to-html"/>
  </target>

  <target name="forrest.check" unless="forrest.home" depends="java5.check">
    <fail message="'forrest.home' is not defined. Please pass -Dforrest.home=&lt;base of Apache Forrest installation&gt; to Ant on the command-line." />
  </target>

  <target name="java5.check" unless="java5.home">
    <fail message="'java5.home' is not defined.  Forrest requires Java 5.  Please pass -Djava5.home=&lt;base of Java 5 distribution&gt; to Ant on the command-line." />
  </target>
	
  <target name="javadoc-dev" depends="compile, ivy-retrieve-javadoc" description="Generate javadoc for hadoop developers">
    <mkdir dir="${build.javadoc.dev}"/>
    <javadoc
      overview="${java.src.dir}/overview.html"
      packagenames="org.apache.hadoop.*"
      destdir="${build.javadoc.dev}"
      author="true"
      version="true"
      use="true"
      windowtitle="${Name} ${version} API"
      doctitle="${Name} ${version} Developer API"
      bottom="Copyright &amp;copy; ${year} The Apache Software Foundation"
      maxmemory="${javadoc.maxmemory}">
        <packageset dir="${java.src.dir}"/>        	
        <link href="${javadoc.link.java}"/>
        <classpath >
          <path refid="classpath" />
          <path refid="javadoc-classpath"/>
          <pathelement path="${java.class.path}"/>
        </classpath>
    	<group title="${ant.project.name}" packages="org.apache.*"/>
    </javadoc>
  </target>	

  <target name="javadoc-uptodate" depends="compile, ivy-retrieve-javadoc">
    <uptodate property="javadoc.is.uptodate">
      <srcfiles dir="${src.dir}">
        <include name="**/*.java" />
        <include name="**/*.html" />
      </srcfiles>
      <mapper type="merge" to="${build.javadoc.timestamp}" />
    </uptodate>
  </target>
 
  <target name="javadoc" description="Generate javadoc" depends="javadoc-uptodate"
       unless="javadoc.is.uptodate">
    <mkdir dir="${build.javadoc}"/>
    <javadoc
      overview="${java.src.dir}/overview.html"
      packagenames="org.apache.hadoop.*"
      destdir="${build.javadoc}"
      author="true"
      version="true"
      use="true"
      windowtitle="${Name} ${version} API"
      doctitle="${Name} ${version} API"
      bottom="Copyright &amp;copy; ${year} The Apache Software Foundation"
      maxmemory="${javadoc.maxmemory}">

        <packageset dir="${java.src.dir}"/>
        <link href="${javadoc.link.java}"/>
        <classpath >
          <path refid="classpath" />
          <path refid="javadoc-classpath"/>
          <pathelement path="${java.class.path}"/>
          <pathelement location="${build.tools}"/>
        </classpath>

    	<group title="${ant.project.name}" packages="org.apache.*"/>
    </javadoc>
  </target>	

  <target name="api-xml" depends="ivy-retrieve-jdiff,javadoc,write-null">
    <javadoc maxmemory="${javadoc.maxmemory}">
       <doclet name="jdiff.JDiff"
               path="${jdiff.jar}:${xerces.jar}">
         <param name="-apidir" value="${jdiff.xml.dir}"/>
         <param name="-apiname" value="hadoop-hdfs ${version}"/>
       </doclet>
       <packageset dir="src/java"/>
       <classpath >
         <path refid="classpath" />
         <path refid="jdiff-classpath" />
         <pathelement path="${java.class.path}"/>
       </classpath>
    </javadoc>
  </target>
	
  <target name="write-null">
	<exec executable="touch">
	   <arg value="${jdiff.home}/Null.java"/>
        </exec>
  </target> 

  <target name="api-report" depends="ivy-retrieve-jdiff,api-xml">
    <mkdir dir="${jdiff.build.dir}"/>
    <javadoc sourcepath="src/java"
             destdir="${jdiff.build.dir}"
	     sourceFiles="${jdiff.home}/Null.java"
	     maxmemory="${javadoc.maxmemory}">
       <doclet name="jdiff.JDiff"
               path="${jdiff.jar}:${xerces.jar}">
         <param name="-oldapi" value="hadoop-hdfs ${jdiff.stable}"/>
         <param name="-newapi" value="hadoop-hdfs ${version}"/>
         <param name="-oldapidir" value="${jdiff.xml.dir}"/>
         <param name="-newapidir" value="${jdiff.xml.dir}"/>
         <param name="-javadocold" value="${jdiff.stable.javadoc}"/>
         <param name="-javadocnew" value="../../api/"/>
         <param name="-stats"/>
       </doclet>
       <classpath >
         <path refid="classpath" />
         <path refid="jdiff-classpath"/>
         <pathelement path="${java.class.path}"/>
       </classpath>
    </javadoc>
  </target>
	
  <target name="changes-to-html" description="Convert CHANGES.txt into an html file">
    <mkdir dir="${build.docs}"/>
    <exec executable="perl" input="CHANGES.txt" output="${build.docs}/changes.html" failonerror="true">
      <arg value="${changes.src}/changes2html.pl"/>
    </exec>
    <copy todir="${build.docs}">
      <fileset dir="${changes.src}" includes="*.css"/>
    </copy>
  </target>

  <!-- ================================================================== -->
  <!-- D I S T R I B U T I O N                                            -->
  <!-- ================================================================== -->
  <!--                                                                    -->
  <!-- ================================================================== -->
  <target name="package" depends="compile, jar, javadoc, docs, api-report, jar-test, ant-tasks"
	  description="Build distribution">
    <mkdir dir="${dist.dir}"/>
    <mkdir dir="${dist.dir}/lib"/>
    <mkdir dir="${dist.dir}/contrib"/>
    <mkdir dir="${dist.dir}/bin"/>
    <mkdir dir="${dist.dir}/docs"/>
    <mkdir dir="${dist.dir}/docs/api"/>
    <mkdir dir="${dist.dir}/docs/jdiff"/>

    <copy todir="${dist.dir}/lib" includeEmptyDirs="false" flatten="true">
      <fileset dir="${common.ivy.lib.dir}"/>
    </copy>

    <copy todir="${dist.dir}/lib" includeEmptyDirs="false">
      <fileset dir="lib">
        <exclude name="**/native/**"/>
      </fileset>
    </copy>

    <subant target="package">
      <!--Pass down the version in case its needed again and the target
      distribution directory so contribs know where to install to.-->
      <property name="version" value="${version}"/>
      <property name="dist.dir" value="${dist.dir}"/>
      <fileset file="${contrib.dir}/build.xml"/>
    </subant>  	

    <copy todir="${dist.dir}/webapps">
      <fileset dir="${build.webapps}"/>
    </copy>

    <copy todir="${dist.dir}"> 
      <fileset file="${build.dir}/${name}-*.jar"/>
    </copy>

    <copy todir="${dist.dir}/conf">
      <fileset dir="${conf.dir}" excludes="**/*.template"/>
    </copy>

    <copy todir="${dist.dir}/docs">
      <fileset dir="${build.docs}"/>
    </copy>

    <copy file="ivy.xml" tofile="${dist.dir}/ivy.xml"/>

    <copy todir="${dist.dir}/ivy">
      <fileset dir="ivy"/>
    </copy>

    <copy todir="${dist.dir}">
      <fileset dir=".">
        <include name="*.txt" />
      </fileset>
    </copy>

    <copy todir="${dist.dir}/src" includeEmptyDirs="true">
      <fileset dir="src" excludes="**/*.template **/docs/build/**/*"/>
    </copy>

    <copy todir="${dist.dir}/" file="build.xml"/>

    <chmod perm="ugo+x" type="file" parallel="false">
        <fileset dir="${dist.dir}/src/contrib/">
          <include name="*/bin/*" />
        </fileset>
    </chmod>

  </target>

  <!-- ================================================================== -->
  <!-- Make release tarball                                               -->
  <!-- ================================================================== -->
  <target name="tar" depends="package" description="Make release tarball">
    <macro_tar param.destfile="${build.dir}/${final.name}.tar.gz">
      <param.listofitems>
        <tarfileset dir="${build.dir}" mode="664">
          <exclude name="${final.name}/contrib/*/bin/*" />
          <include name="${final.name}/**" />
        </tarfileset>
        <tarfileset dir="${build.dir}" mode="755">
          <include name="${final.name}/contrib/*/bin/*" />
        </tarfileset>
      </param.listofitems>
    </macro_tar>
  </target>

  <target name="bin-package" depends="compile, jar, jar-test, ant-tasks" 
		description="assembles artifacts for binary target">
    <mkdir dir="${dist.dir}"/>
    <mkdir dir="${dist.dir}/lib"/>
    <mkdir dir="${dist.dir}/contrib"/>

    <copy todir="${dist.dir}/lib" includeEmptyDirs="false" flatten="true">
      <fileset dir="${common.ivy.lib.dir}"/>
    </copy>

    <copy todir="${dist.dir}/lib" includeEmptyDirs="false">
      <fileset dir="lib">
        <exclude name="**/native/**"/>
      </fileset>
    </copy>

    <subant target="package">
      <!--Pass down the version in case its needed again and the target
      distribution directory so contribs know where to install to.-->
      <property name="version" value="${version}"/>
      <property name="dist.dir" value="${dist.dir}"/>
      <fileset file="${contrib.dir}/build.xml"/>
    </subant>  	

    <copy todir="${dist.dir}/webapps">
      <fileset dir="${build.webapps}"/>
    </copy>

    <copy todir="${dist.dir}"> 
      <fileset file="${build.dir}/${name}-*.jar"/>
    </copy>
    
    <copy todir="${dist.dir}/conf">
      <fileset dir="${conf.dir}" excludes="**/*.template"/>
    </copy>

    <copy file="ivy.xml" tofile="${dist.dir}/ivy.xml"/>

    <copy todir="${dist.dir}/ivy">
      <fileset dir="ivy"/>
    </copy>

    <copy todir="${dist.dir}">
      <fileset dir=".">
        <include name="*.txt" />
      </fileset>
    </copy>
  	
    <copy todir="${dist.dir}/" file="build.xml"/>

  </target>

  <target name="binary" depends="bin-package" description="Make tarball without source and documentation">
    <macro_tar param.destfile="${build.dir}/${final.name}-bin.tar.gz">
      <param.listofitems>
        <tarfileset dir="${build.dir}" mode="664">
          <exclude name="${final.name}/bin/*" />
          <exclude name="${final.name}/src/**" />
          <exclude name="${final.name}/docs/**" />
          <include name="${final.name}/**" />
        </tarfileset>
        <tarfileset dir="${build.dir}" mode="755">
          <include name="${final.name}/bin/*" />
        </tarfileset>
      </param.listofitems>
    </macro_tar>
  </target>

  <!-- ================================================================== -->
  <!-- Perform audit activities for the release                           -->
  <!-- ================================================================== -->
  <target name="rats-taskdef" depends="ivy-retrieve-releaseaudit">
     <typedef format="xml" resource="org/apache/rat/anttasks/antlib.xml" uri="antlib:org.apache.rat.anttasks"
      classpathref="releaseaudit-classpath"/>
  </target>

  <target name="releaseaudit" depends="package, rats-taskdef" description="Release Audit activities">
   <rat:report xmlns:rat="antlib:org.apache.rat.anttasks">
      <fileset dir="${dist.dir}">
        <exclude name="CHANGES.txt"/>
        <exclude name="docs/"/>
        <exclude name="lib/jdiff/"/>
      </fileset>
    </rat:report>
  </target>

  <!-- ================================================================== -->
  <!-- Clean.  Delete the build files, and their directories              -->
  <!-- ================================================================== -->
  <target name="clean" depends="clean-contrib" description="Clean.  Delete the build files, and their directories">
    <delete dir="${build.dir}"/>
    <delete dir="${build-fi.dir}"/>
    <delete dir="${docs.src}/build"/>
    <delete file="${hadoop-hdfs.pom}"/>
    <delete file="${hadoop-hdfs-test.pom}"/>
  </target>

  <target name="veryclean" depends="clean-cache,clean" 
          description="veryclean.  Delete ant maven task and ivy jars">
    <delete file="${ant_task.jar}"/>
    <delete file="${ivy.jar}"/>
  </target>

  <target name="clean-cache" depends="clean" description="Clean. Delete ivy cache">
    <delete dir="${user.home}/.ivy2/cache/org.apache.hadoop/hadoop-core"/>
    <delete dir="${user.home}/.ivy2/cache/org.apache.hadoop/hadoop-core-test"/>
  </target>

  <!-- ================================================================== -->
  <!-- Clean contrib target. For now, must be called explicitly           -->
  <!-- Using subant instead of ant as a workaround for 30569              -->
  <!-- ================================================================== -->
  <target name="clean-contrib">
     <subant target="clean">        
        <fileset file="src/contrib/build.xml"/>
     </subant>  	
  </target>

  <target name="compile-ant-tasks" depends="compile-core">
    <javac
        encoding="${build.encoding}"
        srcdir="${anttasks.dir}"
        includes="org/apache/hadoop/ant/**/*.java"
        destdir="${build.anttasks}"
        debug="${javac.debug}"
        optimize="${javac.optimize}"
        target="${javac.version}"
        source="${javac.version}"
        deprecation="${javac.deprecation}">
        <compilerarg line="${javac.args}"/>
        <classpath refid="classpath"/>
    </javac>
  </target>

  <target name="ant-tasks" depends="jar, compile-ant-tasks">
    <copy file="${anttasks.dir}/org/apache/hadoop/ant/antlib.xml"
          todir="${build.anttasks}/org/apache/hadoop/ant"/>
    <jar destfile="${build.dir}/${ant.final.name}.jar">
      <fileset dir="${build.anttasks}"/>
    </jar>
  </target>

 <target name="clover" depends="clover.setup, clover.info" description="Instrument the Unit tests using Clover.  To use, specify -Dclover.home=&lt;base of clover installation&gt; -Drun.clover=true on the command line."/>

<target name="clover.setup" if="clover.enabled">
   <taskdef resource="cloverlib.xml" classpath="${clover.jar}"/>
   <mkdir dir="${clover.db.dir}"/>
   <clover-setup initString="${clover.db.dir}/hadoop_coverage.db">
     <fileset dir="src" includes="java/**/*"/>
   </clover-setup>
</target>

<target name="clover.info" unless="clover.present">
  <echo>
     Clover not found. Code coverage reports disabled.
  </echo>
</target>

<target name="clover.check">
  <fail unless="clover.present">
  ##################################################################
   Clover not found.
   Please specify -Dclover.home=&lt;base of clover installation&gt;
   on the command line.
  ##################################################################
  </fail>
</target>

<target name="generate-clover-reports" depends="clover.check, clover">
  <mkdir dir="${clover.report.dir}"/>
  <clover-report>
     <current outfile="${clover.report.dir}" title="${final.name}">
     <format type="html"/>
     </current>
  </clover-report>
  <clover-report>
     <current outfile="${clover.report.dir}/clover.xml" title="${final.name}">
     <format type="xml"/>
     </current>
  </clover-report>
</target>

<target name="findbugs.check" depends="check-for-findbugs" unless="findbugs.present">
  <fail message="'findbugs.home' is not defined. Please pass -Dfindbugs.home=&lt;base of Findbugs installation&gt; to Ant on the command-line." />
</target>

<target name="patch.check" unless="patch.file">
  <fail message="'patch.file' is not defined. Please pass -Dpatch.file=&lt;location of patch file&gt; to Ant on the command-line." />
</target>

<target name="test-patch" depends="patch.check,findbugs.check,forrest.check">
  <exec executable="bash" failonerror="true">
    <arg value="${basedir}/src/test/bin/test-patch.sh"/>
    <arg value="DEVELOPER"/>
    <arg value="${patch.file}"/>
    <arg value="${scratch.dir}"/>
    <arg value="${svn.cmd}"/>
    <arg value="${grep.cmd}"/>
    <arg value="${patch.cmd}"/>
    <arg value="${findbugs.home}"/>
    <arg value="${forrest.home}"/>
    <arg value="${basedir}"/>
    <arg value="${java5.home}"/>
  </exec>
</target>

<target name="hudson-test-patch" depends="findbugs.check,forrest.check">
  <exec executable="bash" failonerror="true">
    <arg value="${basedir}/src/test/bin/test-patch.sh"/>
    <arg value="HUDSON"/>
    <arg value="${scratch.dir}"/>
    <arg value="${support.dir}"/>
    <arg value="${ps.cmd}"/>
    <arg value="${wget.cmd}"/>
    <arg value="${jiracli.cmd}"/>
    <arg value="${svn.cmd}"/>
    <arg value="${grep.cmd}"/>
    <arg value="${patch.cmd}"/>
    <arg value="${findbugs.home}"/>
    <arg value="${forrest.home}"/>
    <arg value="${eclipse.home}"/>
    <arg value="${python.home}"/>
    <arg value="${basedir}"/>
    <arg value="${trigger.url}"/>
    <arg value="${jira.passwd}"/>
    <arg value="${java5.home}"/>
    <arg value="${curl.cmd}"/>
    <arg value="${defect}"/>
  </exec>
</target>
	
  <target name="eclipse-files" depends="init"
          description="Generate files for Eclipse">
    <pathconvert property="eclipse.project">
      <path path="${basedir}"/>
      <regexpmapper from="^.*/([^/]+)$$" to="\1" handledirsep="yes"/>
    </pathconvert>
    <copy todir="." overwrite="true">
      <fileset dir=".eclipse.templates">
      	<exclude name="**/README.txt"/>
      </fileset>
      <filterset>
        <filter token="PROJECT" value="${eclipse.project}"/>
      </filterset>
    </copy>
  </target>

  <target name="ivy-init-dirs">
    <mkdir dir="${build.ivy.dir}" />
    <mkdir dir="${build.ivy.lib.dir}" />
    <mkdir dir="${build.ivy.report.dir}" />
    <mkdir dir="${build.ivy.maven.dir}" />
  </target>

  <target name="ivy-probe-antlib" >
    <condition property="ivy.found">
      <typefound uri="antlib:org.apache.ivy.ant" name="cleancache"/>
    </condition>
  </target>

  <target name="ivy-download" description="To download ivy" unless="offline">
    <get src="${ivy_repo_url}" dest="${ivy.jar}" usetimestamp="true"/>
  </target>

  <target name="ant-task-download" description="To download mvn-ant-task" unless="offline">
    <get src="${ant_task_repo_url}" dest="${ant_task.jar}" usetimestamp="true"/>
  </target>

  <target name="mvn-taskdef" depends="ant-task-download">
     <path id="mvn-ant-task.classpath" path="${ant_task.jar}"/> 
     <typedef resource="org/apache/maven/artifact/ant/antlib.xml" 
         uri="urn:maven-artifact-ant" classpathref="mvn-ant-task.classpath"/>
  </target>   

  
  <target name="mvn-install-hdfs" depends="mvn-taskdef,jar,set-version">
     <artifact:pom file="${hadoop-hdfs.pom}" id="hadoop.hdfs"/>
     <artifact:install file="${hadoop-hdfs.jar}">
        <pom refid="hadoop.hdfs"/>
     </artifact:install>
  </target>

  <target name="mvn-install" depends="mvn-taskdef,jar,jar-hdfs-test,set-version">
     <artifact:pom file="${hadoop-hdfs.pom}" id="hadoop.hdfs"/>
     <artifact:pom file="${hadoop-hdfs-test.pom}" id="hadoop.hdfs.test"/>
     <artifact:install file="${hadoop-hdfs.jar}">
        <pom refid="hadoop.hdfs"/>
     </artifact:install>
     <artifact:install file="${hadoop-hdfs-test.jar}">
        <pom refid="hadoop.hdfs.test"/>
     </artifact:install>
  </target>

  <target name="mvn-deploy" depends="mvn-taskdef, jar, jar-hdfs-test, set-version">
     <property name="repourl" value="https://repository.apache.org/content/repositories/snapshots" />
     <artifact:pom file="${hadoop-hdfs.pom}" id="hadoop.hdfs"/>
     <artifact:pom file="${hadoop-hdfs-test.pom}" id="hadoop.hdfs.test"/>

     <artifact:install-provider artifactId="wagon-http" version="1.0-beta-2"/>
     <artifact:deploy file="${hadoop-hdfs.jar}">
         <remoteRepository id="apache.snapshots.https" url="${repourl}"/>
         <pom refid="hadoop.hdfs"/>
     </artifact:deploy>
     <artifact:deploy file="${hadoop-hdfs-test.jar}">
         <remoteRepository id="apache.snapshots.https" url="${repourl}"/>
         <pom refid="hadoop.hdfs.test"/>
     </artifact:deploy>
  </target>
  
  <target name="set-version">
    <delete file="${basedir}/ivy/hadoop-hdfs.xml"/>
    <delete file="${basedir}/ivy/hadoop-hdfs-test.xml"/>
    <copy file="${basedir}/ivy/hadoop-hdfs-template.xml" tofile="${basedir}/ivy/hadoop-hdfs.xml"/>
    <copy file="${basedir}/ivy/hadoop-hdfs-test-template.xml" tofile="${basedir}/ivy/hadoop-hdfs-test.xml"/>
    <replaceregexp byline="true">
      <regexp pattern="@version"/>
      <substitution expression="${version}"/>
      <fileset dir="${basedir}/ivy">
        <include name="hadoop-hdfs.xml"/>
      </fileset>
    </replaceregexp>
    <replaceregexp byline="true">
      <regexp pattern="@version"/>
      <substitution expression="${version}"/>
      <fileset dir="${basedir}/ivy">
        <include name="hadoop-hdfs-test.xml"/>
      </fileset>
    </replaceregexp>
  </target>
 

  <!--
  To avoid Ivy leaking things across big projects, always load Ivy in the same classloader.
  Also note how we skip loading Ivy if it is already there, just to make sure all is well.
  -->
  <target name="ivy-init-antlib" depends="ivy-download,ivy-init-dirs,ivy-probe-antlib" unless="ivy.found">
    <typedef uri="antlib:org.apache.ivy.ant" onerror="fail"
      loaderRef="ivyLoader">
      <classpath>
        <pathelement location="${ivy.jar}"/>
      </classpath>
    </typedef>
    <fail >
      <condition >
        <not>
          <typefound uri="antlib:org.apache.ivy.ant" name="cleancache"/>
        </not>
      </condition>
      You need Apache Ivy 2.0 or later from http://ant.apache.org/
      It could not be loaded from ${ivy_repo_url}
    </fail>
  </target>


  <target name="ivy-init" depends="ivy-init-antlib" >

    <!--Configure Ivy by reading in the settings file
        If anyone has already read in a settings file into this settings ID, it gets priority
    -->
    <ivy:configure settingsid="${ant.project.name}.ivy.settings" file="${ivysettings.xml}" override='false'/>
  </target>

  <target name="ivy-resolve" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings"/>
  </target>

  <target name="ivy-resolve-javadoc" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="javadoc"/>
  </target>

  <target name="ivy-resolve-releaseaudit" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="releaseaudit"/>
  </target>

  <target name="ivy-resolve-test" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="test" />
  </target>

  <target name="ivy-resolve-common" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="common" />
  </target>

  <target name="ivy-resolve-jdiff" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="jdiff" />
  </target>

  <target name="ivy-resolve-checkstyle" depends="ivy-init">
    <ivy:resolve settingsRef="${ant.project.name}.ivy.settings" conf="checkstyle"/>
  </target>

  <target name="ivy-retrieve" depends="ivy-resolve"
    description="Retrieve Ivy-managed artifacts">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
  </target>

  <target name="ivy-retrieve-checkstyle" depends="ivy-resolve-checkstyle"
    description="Retrieve Ivy-managed artifacts for the checkstyle configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="checkstyle-classpath" conf="checkstyle"/>
  </target>

  <target name="ivy-retrieve-jdiff" depends="ivy-resolve-jdiff"
    description="Retrieve Ivy-managed artifacts for the javadoc configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="jdiff-classpath" conf="jdiff"/>
  </target>

  <target name="ivy-retrieve-javadoc" depends="ivy-resolve-javadoc"
    description="Retrieve Ivy-managed artifacts for the javadoc configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="javadoc-classpath" conf="javadoc"/>
  </target>

  <target name="ivy-retrieve-test" depends="ivy-resolve-test"
    description="Retrieve Ivy-managed artifacts for the test configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="ivy-test.classpath" conf="test"/>
  </target>

  <target name="ivy-retrieve-common" depends="ivy-resolve-common"
    description="Retrieve Ivy-managed artifacts for the compile configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}"/>
    <ivy:cachepath pathid="ivy-common.classpath" conf="common"/>
  </target>

  <target name="ivy-retrieve-releaseaudit" depends="ivy-resolve-releaseaudit"
    description="Retrieve Ivy-managed artifacts for the compile configurations">
    <ivy:retrieve settingsRef="${ant.project.name}.ivy.settings"
      pattern="${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}" />
    <ivy:cachepath pathid="releaseaudit-classpath" conf="releaseaudit"/>
  </target>

  <target name="ivy-report" depends="ivy-resolve-releaseaudit"
    description="Generate">
    <ivy:report todir="${build.ivy.report.dir}" settingsRef="${ant.project.name}.ivy.settings"/>
    <echo>
      Reports generated:${build.ivy.report.dir}
    </echo>
  </target>

</project>
